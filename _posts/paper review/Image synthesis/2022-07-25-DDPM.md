---
title: "Denoising Diffusion Probabilistic Models"
# image : ""
date: '2022-07-25'
categories: [Paper review, Image synthesis]
# tags: [tag] 
author: saha
math: true
mermaid: true
pin : false
---

<img src="/assets/images/DDPM_1.png" width="100%" height="100%"> 
# Abstract

We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models nat- urally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN. Our implementation is available at [https://github.com/hojonathanho/diffusion](https://github.com/hojonathanho/diffusion).

# Introduction

Diffusion probabilistic model(diffusion model)은 Markov chain인 forward process가 주어졌을 때, 그 backward process를 예측하고자 하는 model이다. Forward process가 소량의 Gaussian noise인 경우, backward process역시 Gaussian으로 근사할 수 있기 때문에 비교적 간단하게 model을 학습시킬 수 있다. 

본 논문(DDPM)은 diffusion model을 이용해 high-quality sample을 만드는 것이 가능하고, 다른 generative model보다 좋은 성능을 갖는 경우도 있다고 말한다. 

<!-- In addition, we show that a certain parameterization of diffusion models reveals an equivalence with denoising score matching over multiple noise levels during training and with annealed Langevin dynamics during sampling -->

<img src="/assets/images/DDPM_2.png" width="100%" height="100%">*DDPM의 대략적인 구조. q가 forward process, p가 backward process 이다.*

# Diffusion model

## Forward process

Diffusion model은 latent $\mathbf{x}_1, ..., \mathbf{x}_T$와 forward process $q$로 이루어져 있다. 이때 $q$는 아주 작은 Gaussian noise로, mean과 variance는 특정한 schedule $\beta_1, ..., \beta_T$에 의해 결정된다(\ref{eq1}).

---

$$
q(\mathbf{x}_t|\mathbf{x}_{t-1}) := \mathcal{N}(\mathbf{x}_t;\sqrt{1-\beta_t}\mathbf{x}_{t-1}, \beta_t\mathbf{I}) \label{eq1} \tag{1}
$$

---

Forward process는 어떠한 image $\mathbf{x}_0$에 Gaussian noise $q$를 $T$번 apply하는 것으로 생각할 수 있으며, 최종적인 latent $\mathbf{x}_T$ 역시 Gaussian noise가 된다. 추가적으로 $q$는 markov chain이기 때문에, 아래 식이 성립한다(\ref{eq2}). 

---

$$
q(\mathbf{x}_t|\mathbf{x}_0) = \prod_{i=1}^t q(\mathbf{x}_t|\mathbf{x}_{t-1}) \label{eq2} \tag{2}
$$

---

이를 이용하면 $\mathbf{x}_t$를 $\mathbf{x}_0$를 이용해서 나타낼 수 있다(\ref{eq3}). 

---

$$
\begin{align}
    \mathbf{x}_t &= \sqrt{\alpha_t}\mathbf{x}_{t-1} + \sqrt{1-\alpha_t}\epsilon \\
    &= \sqrt{\alpha_t \alpha_{t-1}}\mathbf{x}_{t-2} + \sqrt{1-\alpha_t\alpha_{t-1}}\epsilon \\
    &= ...\\
    &= \sqrt{\bar{\alpha}_t}\mathbf{x}_{0} + \sqrt{1-\bar{\alpha}_t}\epsilon \label{eq3} \tag{3}
\end{align}
$$

---

이때 $\alpha_t = 1 - \beta_t$, $\bar{\alpha}_t = \prod _{i=1}^{t}$, $\epsilon = \mathcal{N}(0, \mathbf{I})$ 이다. 

## Backward process

Forward process $q$를 이용해서 backward process $p$를 예측하는것이 DDPM의 목표이다. 이때 $q$와 마찬가지로 $p$도 Markov chain이다(\ref{eq4}). 

---

$$
p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_{t}) := \mathcal{N}(\mathbf{x}_{t}; \mathbf{\mu}_{\theta}(\mathbf{x}_{t},t), \mathbf{\Sigma}_{\theta}(\mathbf{x}_{t}, t)), \quad p_\theta(\mathbf{x}_{0}|\mathbf{x}_{T}) = \prod_{t=1}^Tp_\theta(\mathbf{x}_{t-1}|\mathbf{x}_{t}) \label{eq4} \tag{4}
$$

---

## Learning backward process

$p$는 Negative log likelihood의 upper bound를 이용해 학습시킬 수 있다(\ref{eq5}). 

---

$$
\mathbb{E}[-\log p_\theta(\mathbf{x}_{0})] \le \mathbb{E}_q\left[-\log p_\theta(\mathbf{x}_{T}) - \sum_{t \ge 1}\log\frac{p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_{t})}{q(\mathbf{x}_{t}|\mathbf{x}_{t-1})}\right] := L \label{eq5} \tag{5}
$$

---

위 식을 간단하게 하면, 다음과 같은 식을 얻을 수 있다(\ref{eq6}). 

---

$$
L = \mathbb{E}_q\left[ \underset{L_T}{\underbrace{D_{KL}(q(\mathbf{x}_T|\mathbf{x}_0)||p(\mathbf{x}_T))}} + \sum_{t>1} \underset{L_{t-1}}{\underbrace{D_{KL}(q(\mathbf{x}_{t-1}|\mathbf{x}_t,\mathbf{x}_0)||p(\mathbf{x}_{t-1}|\mathbf{x}_t))}} \underset{L_0}{\underbrace{-\log p_\theta(\mathbf{x}_0|\mathbf{x}_1)}}\right] \label{eq6} \tag{6}
$$

---

위 식들의 자세한 유도과정은 [DDPM 논문](https://proceedings.neurips.cc/paper/2020/hash/4c5bcfec8584af0d967f1ab10179ca4b-Abstract.html)의 appendix를 참고하길 바란다. 

### $L_T$

DDPM에서는 $\beta_t$를 학습시키지 않고 고정된 값을 사용한다. 그렇기 때문에 forward process $q$에는 learnable parameter가 존재하지 않고, $p(\mathbf{x}_T)$도 Gaussian noise이기 때문에 $L_T$는 상수가 된다. 

### $L_{T-1}, ..., L_1$

수식 \ref{eq4}를 보면, backward process 의 mean과 variance는 모두 learnable 하다. 하지만 DDPM에서는 $p$의 variance $\sigma^2$를 $q$와 동일하다고 놓고 mean만 학습을 시켰다. 이러한 경우에 Loss term $L_{t-1}$은 다음과 같이 정리할 수 있다(\ref{eq7}). 

---

$$
L_{t-1} = \mathbb{E}_q \left[ \frac{1}{2\sigma_t^2} || \tilde{\mathbf{\mu}}_t(\mathbf{x}_t, \mathbf{x}_0) - \mathbf{\mu}_\theta(\mathbf{x}_t, t)||^2 \right] + C \label{eq7} \tag{7}
$$

---

이때 $C$는 상수부분으로, 학습할 때 무시할 수 있다. Equation \ref{eq3}을 이용해 위 식을 간단하게 하면, 다음과 같은 식을 얻을 수 있다(\ref{eq8}). 

---

$$
L_{t-1} - C = \mathbb{E}_{\mathbf{x}_0, \epsilon} \left[ \frac{1}{2\sigma_t^2}||\frac{1}{\sqrt{\alpha_t}}\left( \mathbf{x}_t - \frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}}\epsilon \right) - \mathbf{\mu}_\theta(\mathbf{x}_t(\mathbf{x}_0, \epsilon), t)||^2 \right] \label{eq8} \tag{8}
$$

---

$\epsilon$은 Gaussian noise 이다. 여기서 DDPM의 저자들은 $\mathbf{\mu}_\theta$ 를 $\frac{1}{\sqrt{\alpha_t}}\left( \mathbf{x}_t - \frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}} \epsilon _\theta(\mathbf{x}_t, t) \right)$ 로 parameterize 했는데, 이는 $p$와 $q$의 mean term을 서로 비슷하게 만들어주기 위함이다. U-Net 구조의 model을 사용했는데, PixelCNN++와 비슷한 구조를 사용했다고 한다.  그러면 결과적으로 아래와 같은 최종 loss function을 얻을 수 있다(\ref{eq9}). 

---

$$
L_{t-1} = \mathbb{E}_{\mathbf{x}_0, \epsilon} \left[ \frac{\beta^2_t}{2\sigma^2_t\alpha_t(1-\bar{\alpha}_t)} ||\epsilon - \epsilon _\theta(\sqrt{\bar{\alpha}\mathbf{x}_0} + \sqrt{1-\bar{\alpha_t}}\epsilon, t)||^2 \right] \label{eq9} \tag{9}
$$

---

실제로 학습을 할 때는, 앞의 상수부분 $\frac{\beta^2_t}{2\sigma^2_t\alpha_t(1-\bar{\alpha}_t)}$ 를 지우고 하는 것이 실험적으로 더 좋은 결과를 보여줬다고 한다. 

## Reconstructing $\mathbf{x}_0$

Reconstruction은 $\mathbf{x}_T$에서 시작해서 순차적으로 $\mathbf{x}_0$ 까지 generate 하는 방식으로 진행된다(\ref{eq10}). 

---

$$
\mathbf{x}_{t-1} = \mathbf{\mu}(\mathbf{x}_t, t) + \sigma_t\mathbf{z} = \frac{1}{\sqrt{\alpha_t}}\left( \mathbf{x}_t - \frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}} \epsilon _\theta(\mathbf{x}_t, t) \right) + \sigma_t\mathbf{z} \label{eq10} \tag{10}
$$

---

## Overall algorithm

위에서 설명한 training과 reconstruction의 algorithm은 아래와 같다. 

<img src="/assets/images/DDPM_3.png" width="100%" height="100%"> 

# Experiments

$T = 1000$, $\beta_1 = 10^{-4}, ..., \beta_T = 0.02$ 의 linear schedule로 실험을 진행했다. 

<img src="/assets/images/DDPM_4.png" width="100%" height="100%"> 

더 자세한 설명은 [DDPM 논문](https://proceedings.neurips.cc/paper/2020/hash/4c5bcfec8584af0d967f1ab10179ca4b-Abstract.html)을 참고하길 바란다. 

# Conclusion

We have presented high quality image samples using diffusion models, and we have found connections among diffusion models and variational inference for 
training Markov chains, denoising score matching and annealed Langevin dynamics (and energy-based models by extension), autoregressive models, and progressive lossy compression.
Since diffusion models seem to have excellent inductive biases for image data, we look forward to investigating their utility in other data modalities and as components in other
types of generative models and machine learning systems.
