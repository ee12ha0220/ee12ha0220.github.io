---
title: "Image Super-Resolution via Iterative Refinement"
# image : ""
date: '2022-08-08'
categories: [Paper review, Image synthesis]
# tags: [tag] 
author: saha
math: true
mermaid: true
pin : false
---

# Abstract

We present SR3, an approach to image Super-Resolution via Repeated Refinement. SR3 adapts denoising diffusion probabilistic models [17, 48] to conditional image generation and performs super-resolution through a stochastic iterative denoising process. Output generation starts with pure Gaussian noise and iteratively refines the noisy output using a U-Net model trained on denoising at various noise levels. SR3 exhibits strong performance on super-resolution tasks at different magnification factors, on faces and natural images. We conduct human evaluation on a standard 8× face super-resolution task on CelebA-HQ, comparing with SOTA GAN methods. SR3 achieves a fool rate close to 50%, suggesting photo-realistic outputs, while GANs do not exceed a fool rate of 34%. We further show the effectiveness of SR3 in cascaded image generation, where generative models are chained with super-resolution models, yielding a competitive FID score of 11.3 on ImageNet.

# Introduction

Single-image super-resolution은 input된 low-resolution image와 동일한 quality의 high-resolution image를 generate하는 것이다. 이는 colorization, in-painting, de-blurring등과 같은 image-to-image translation task의 범주에 속한다. 이러한 문제들과 마찬가지로 single-image super-resolution 역시 high-resolution image의 distribution이 일반적인 parametric distribution(예를 들면, multivariate Gaussian)으로 표현되기가 힘들기 때문에 이 문제 역시 어려운 문제가 된다. Autoregressive models, VAEs, Normalizing Flows(NFs), 그리고 GANs같은 deep-generative model들은 이러한 문제들을 해결하는 데에 좋은 성능을 보이지만, 이들은 너무 heavy하거나 성능 부분에 약간의 issue가 있거나, 학습을 하는 것이 너무 어려운 등 각종 문제들이 있다. 

본 논문(SR3)에서는 이를 해결하고자 ***Super-Resolution via Repeated Refinement*** 을 제시한다. 이는 최근에 뛰어난 성능을 보인 [DDPM](https://ee12ha0220.github.io/posts/DDPM/)과 비슷하지만, 사용되는 U-Net의 구조에 변화를 줘서 conditional generation에 적합하게 변화시켰다. 

# Conditional Denoising Diffusion model

Conditional denoising diffusion model은 source image $\mathbf{x}$와 target image $\mathbf{y}$에 대해, $p(\mathbf{y}\|\mathbf{x})$의 parametric approximation을 알아내는 것을 목표로 한다. 이 과정에서 stochastic iterative refinement가 사용되는데, 이는 처음 distribution에 아주 작은 noise를 순차적으로 줘서 원하는 distribution으로 보내는 것이다. 즉, pure noise $\mathbf{y}_T \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$에서 시작해서, 학습된 conditional transition distribution $p _\theta(\mathbf{y} _{t-1}\|\mathbf{y} _{t}, \mathbf{x})$를 통해 $(\mathbf{y} _{T-1}, \mathbf{y} _{T-2}, ..., \mathbf{y} _{0})$ 의 과정을 거쳐 $\mathbf{y} _{0} \sim p(\mathbf{y}\|\mathbf{x})$를 얻는 것을 목표로 한다. 학습 과정에서 intermediate image들의 distribution($\mathbf{y} _t$)는 주어진 target image $\mathbf{y} _0$에서 시작해 작은 Gaussian noise들인 forward process $q(\mathbf{y} _t\|\mathbf{y} _{t-1})$를 순차적으로 가해줘서 얻을 수 있다. 

<img src="/assets/images/SR3_1.png" width="100%" height="100%">*Conditional diffusion model의 구조. Forward process $q$를 이용해 여러 intermediate image들을 만들어내고, 이들을 이용해 backward process $p$를 학습한다.*

[DDPM](https://ee12ha0220.github.io/posts/DDPM/)과 동일하게 forward와 backward process가 진행되기 때문에, 같은 수학적 공식을 따른다. 다만 conditional한 diffusion model이기 때문에, source image $\mathbf{x}$도 포함해서 network가 만들어진다. 

<img src="/assets/images/SR3_2.png" width="100%" height="100%">*SR3의 전체 algorithm. DDPM과 동일하지만, network에 $\mathbf{x}$가 포함되어 있다.*

## SR3 model architecture



