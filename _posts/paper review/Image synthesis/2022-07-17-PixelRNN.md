---
title: "Pixel Recurrent Neural Networks"
# image : ""
date: '2022-07-17'
categories: [Paper review, Image synthesis]
# tags: [tag] 
author: saha
math: true
mermaid: true
pin : false
--- 

# Abstract

Modeling the distribution of natural images is
a landmark problem in unsupervised learning.
This task requires an image model that is at
once expressive, tractable and scalable. We
present a deep neural network that sequentially
predicts the pixels in an image along the two
spatial dimensions. Our method models the discrete
probability of the raw pixel values and encodes
the complete set of dependencies in the
image. Architectural novelties include fast two dimensional
recurrent layers and an effective use
of residual connections in deep recurrent networks.
We achieve log-likelihood scores on natural
images that are considerably better than the
previous state of the art. Our main results also
provide benchmarks on the diverse ImageNet
dataset. Samples generated from the model appear
crisp, varied and globally coherent.

# Introduction

Generative image modeling은 여러 방면에서 뛰어난 성능을 보이지만, high-dimensional한 image들의 distribution을 알아내는 것은 어려운 일이다. 추가적으로 generative modeling은 tractable하면서 scalable한 model을 만드는 것을 목표로 하는데, 기존의 연구들은 stochastic latent variable을 사용하는 VAE같이 scalability는 잘 챙겼지만 tractability는 잘 챙기지 못하는 모습을 보여준다. 본 논문(PixelRNN)에서는 RNN을 이용해서 image내의 pixel의 관계를 학습해 tractability를 얻고자 한다. 구체적으로, LSTM을 row방향으로 적용하는 'Row LSTM', diagonal 방향으로 적용하는 'Diagonal BiLSTM', 그리고 masked CNN을 사용하는 'PixelCNN'을 소개한다. 

# Main idea

PixelRNN에서는 이전 context를 기반으로, 현재 pixel이 될 수 있는 값의 conditional distribution을 구하는 것을 목표로 한다. $n\times n$크기의 image $\mathbf{x}$에 대해, probability $p(\mathbf{x})$는 다음과 같이 정의된다(\ref{eq1}).

---

$$
p(\mathbf{x}) = \prod_{i=1}^{n^2}p(x_i|x_1, ..., x_{i-1}) \label{eq1} \tag{1}
$$

---

$p(x_i\|x_1, ..., x_{i-1})$ 는 pixel $x_1, ..., x_{i-1}$의 값이 주어졌을 때, 다음 pixel $x_i$의 probability로 해석할 수 있다. 

<img src="/assets/images/PixelRNN_1.png" width="50%" height="50%">*PixelRNN의 main idea. 이전 pixel들의 값이 주어졌을 때, 현재 pixel 값의 probability를 알고자 한다.* 

# Pixel Recurrent Neural Networks

PixerRNN에서 사용한 model에는 Row LSTM, Diagonal BiLSTM, PixelCNN의 3가지가 있다. 

<img src="/assets/images/PixelRNN_2.png" width="80%" height="80%">*PixelRNN에서 사용한 3가지 model.* 


## Row LSTM

Row LSTM은 위에서부터 순서대로 row의 feature을 계산하는 unidirectional layer이다. 각 pixel에 대해 pixel 윗부분에 존재하는 삼각형 부분의 context를 계산하게 되는데, LSTM layer의 한 step은 다음과 같이 쓸 수 있다(\ref{eq2}).

---

$$
\begin{align}
    [\mathbf{o}_i, \mathbf{f}_i, \mathbf{i}_i, \mathbf{g}_i] &= \sigma(\mathbf{K}^{ss}\circledast\mathbf{h}_{i-1} + \mathbf{K}^{is}\circledast \mathbf{x}_i) \\ 
    \mathbf{c}_i &= \mathbf{f}_i \odot \mathbf{c}_{i-1} + \mathbf{i}_i \odot \mathbf{g}_i \\
    \mathbf{h}_i &= \mathbf{o}_i \odot \tanh(\mathbf{c}_i)
\end{align} \label{eq2} \tag{2}
$$

---

Row LSTM은 삼각형 모양의 receptive field를 갖고 있기 때문에, 전체 context를 참고하는 것은 불가능하다. 

## Diagonal BiLSTM

Diagonal BiLSTM은 computation 과정에서 이전의 context를 모두 참고하기 위해 고안되었으며, input map을 row마다 한칸씩 차이나게 skew시켜서 LSTM을 진행해 줬다. 그러면 각 column에 있는 pixel들은 그보다 왼쪽 위에 있는 pixel들을 참고하면 이전에 등장한 모든 context를 참고할 수 있게되고, computation을 column 순서대로 하면 되기 때문에 순서가 꼬이는 일도 없다. 

<img src="/assets/images/PixelRNN_3.png" width="80%" height="80%">*Diagonal BiLSTM에서는 이 그림처럼 input map을 skew하게 된다. 이전 column에 대한 정보만으로 각 pixel 이전의 모든 context를 참고할 수 있다.* 

## PixelCNN

LSTM layer은 이론적으로 unbounded dependency range를 갖고 있다. 하지만 이 때문에 각 computational cost도 같이 올라간다. 그렇기 저자들은 receptive field는 넓게 하지만 unbounded하지는 않은 CNN을 사용하는 'PixelCNN'을 제시했다. 이 과정에서 CNN에 mask를 씌워 미래 pixel의 값을 참고하지 않도록 했다. 

## Multi-Scale PixelRNN

Multi-Scale PixelRNN은 unconditional PixelRNN과 추가적인 conditional PixelRNN으로 이루어져 있다. 먼저 unconditional PixelRNN을 이용해 original image에서 subsample된 $s\times s$크기의 smaller image를 만들어낸다. 그 다음 이를 additional input으로 받아 conditional PixelRNN을 이용해 원래 크기의 image를 만든다. 이때 처음 생성된 image는 upsample되어 input으로 사용된다. 


Diffusion probabilistic model(diffusion model)은 Markov chain인 forward process가 주어졌을 때, 그 backward process를 예측하고자 하는 model이다. Forward process가 소량의 Gaussian noise인 경우, backward process역시 Gaussian으로 근사할 수 있기 때문에 비교적 간단하게 model을 학습시킬 수 있다. 

<img src="/assets/images/PixelRNN_4.png" width="50%" height="50%">*Multi-scale PixelRNN. 하늘색 pixel이 unconditional PixelRNN으로 만든 small image이다.*

# Training details

MNIST, CIFAR-10, ImageNet dataset을 이용해서 실험을 진행했다. Loss로는 Generative model에서 많이 사용하는 negative log likelihood(NLL)를 사용했다. 더 자세한 사항은 [PixelRNN paper](https://arxiv.org/abs/1601.06759)을 참조하길 바란다. 

# Reuslt

이전의 연구들보다 좋은 성능을 보였다. Diagonal BiLSTM이 가장 좋은 성능을 보였지만, Row LSTM과 PixelCNN도 좋은 결과를 보였다. 더 자세한 사항은 [PixelRNN paper](https://arxiv.org/abs/1601.06759)을 참조하길 바란다. 

<img src="/assets/images/PixelRNN_5.png" width="80%" height="80%">

# Conclusion

In this paper we significantly improve and build upon deep recurrent neural networks as generative models for natural images. We have described novel two-dimensional LSTM layers: the Row LSTM and the Diagonal BiLSTM, that scale more easily to larger datasets. The models were trained to model the raw RGB pixel values. We treated the pixel values as discrete random variables by using a softmax layer in the conditional distributions. We employed masked convolutions to allow PixelRNNs to model full dependencies between the color channels. We proposed and evaluated architectural improvements in these models resulting in PixelRNNs with up to 12 LSTM layers.
We have shown that the PixelRNNs significantly improve the state of the art on the MNIST and CIFAR-10 datasets. We also provide new benchmarks for generative image modeling on the ImageNet dataset. Based on the samples and completions drawn from the models we can conclude that the PixelRNNs are able to model both spatially local and long-range correlations and are able to produce images that are sharp and coherent. Given that these models improve as we make them larger and that there is practically unlimited data available to train on, more computation and larger models are likely to further improve the results.