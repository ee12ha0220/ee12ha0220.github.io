---
title: "Image Super-Resolution via Iterative Refinement"
# image : ""
date: '2022-08-13'
categories: [Paper review, Image synthesis]
# tags: [tag] 
author: saha
math: true
mermaid: true
pin : false
---

# Abstract

We present SR3, an approach to image Super-Resolution via Repeated Refinement. SR3 adapts denoising diffusion probabilistic models [17, 48] to conditional image generation and performs super-resolution through a stochastic iterative denoising process. Output generation starts with pure Gaussian noise and iteratively refines the noisy output using a U-Net model trained on denoising at various noise levels. SR3 exhibits strong performance on super-resolution tasks at different magnification factors, on faces and natural images. We conduct human evaluation on a standard 8× face super-resolution task on CelebA-HQ, comparing with SOTA GAN methods. SR3 achieves a fool rate close to 50%, suggesting photo-realistic outputs, while GANs do not exceed a fool rate of 34%. We further show the effectiveness of SR3 in cascaded image generation, where generative models are chained with super-resolution models, yielding a competitive FID score of 11.3 on ImageNet.

# Introduction

Single-image super-resolution은 input된 low-resolution image와 동일한 quality의 high-resolution image를 generate하는 것이다. 이는 colorization, in-painting, de-blurring등과 같은 image-to-image translation task의 범주에 속한다. 이러한 문제들과 마찬가지로 single-image super-resolution 역시 high-resolution image의 distribution이 일반적인 parametric distribution(예를 들면, multivariate Gaussian)으로 표현되기가 힘들기 때문에 이 문제 역시 어려운 문제가 된다. Autoregressive models, VAEs, Normalizing Flows(NFs), 그리고 GANs같은 deep-generative model들은 이러한 문제들을 해결하는 데에 좋은 성능을 보이지만, 이들은 너무 heavy하거나 성능 부분에 약간의 issue가 있거나, 학습을 하는 것이 너무 어려운 등 각종 문제들이 있다. 

본 논문(SR3)에서는 이를 해결하고자 ***Super-Resolution via Repeated Refinement*** 을 제시한다. 이는 최근에 뛰어난 성능을 보인 [DDPM](https://ee12ha0220.github.io/posts/DDPM/)과 비슷하지만, 사용되는 U-Net의 구조에 변화를 줘서 conditional generation에 적합하게 변화시켰다. 

# Conditional Denoising Diffusion model

Conditional denoising diffusion model은 source image $\mathbf{x}$와 target image $\mathbf{y}$에 대해, $p(\mathbf{y}\|\mathbf{x})$의 parametric approximation을 알아내는 것을 목표로 한다. 이 과정에서 stochastic iterative refinement가 사용되는데, 이는 처음 distribution에 아주 작은 noise를 순차적으로 줘서 원하는 distribution으로 보내는 것이다. 즉, pure noise $\mathbf{y}_T \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$에서 시작해서, 학습된 conditional transition distribution $p _\theta(\mathbf{y} _{t-1}\|\mathbf{y} _{t}, \mathbf{x})$를 통해 $(\mathbf{y} _{T-1}, \mathbf{y} _{T-2}, ..., \mathbf{y} _{0})$ 의 과정을 거쳐 $\mathbf{y} _{0} \sim p(\mathbf{y}\|\mathbf{x})$를 얻는 것을 목표로 한다. 학습 과정에서 intermediate image들의 distribution($\mathbf{y} _t$)는 주어진 target image $\mathbf{y} _0$에서 시작해 작은 Gaussian noise들인 forward process $q(\mathbf{y} _t\|\mathbf{y} _{t-1})$를 순차적으로 가해줘서 얻을 수 있다. 

<img src="/assets/images/SR3_1.png" width="100%" height="100%">*Conditional diffusion model의 구조. Forward process $q$를 이용해 여러 intermediate image들을 만들어내고, 이들을 이용해 backward process $p$를 학습한다.*

[DDPM](https://ee12ha0220.github.io/posts/DDPM/)과 동일하게 forward와 backward process가 진행되기 때문에, 같은 수학적 공식을 따른다. 다만 conditional한 diffusion model이기 때문에, source image $\mathbf{x}$도 포함해서 network가 만들어진다. 

<img src="/assets/images/SR3_2.png" width="100%" height="100%">*SR3의 전체 algorithm. DDPM과 동일하지만, network에 $\mathbf{x}$가 포함되어 있다.*

## SR3 model architecture

[ScoreSDE](https://ee12ha0220.github.io/posts/ScoreSDE/)의 변화를 가져와서 사용했는데, Residual block을 BigGAN의 것으로 교체하고, skip connection을 $1/\sqrt{2}$로 rescale하고, 더 많은 residual block을 사용했다. Low-resolution input $\mathbf{x}$는 bicubic interpolation을 이용해서 upsample 된 후에, $\mathbf{y} _t$와 concatenate되어 U-Net으로 전달된다. 

<img src="/assets/images/SR3_3.png" width="60%" height="60%">*SR3 U-Net의 구조. Input 단계에서 $\mathbf{x}$ $\mathbf{y} _t$가 concatenate된다.*

# Training details

Flickr-Faces-HQ(FFHQ), CelebA-HQ, ImageNet 1K dataset을 이용해서 학습되었다. Evaluation metric에는 PSNR과 SSIM이 사용되었고, 2-alternative forced-choice(2AFC)를 기반으로 측정된 Fool rate도 사용했다. 더 자세한 내용은 [SR3 paper](https://arxiv.org/abs/2104.07636)를 참조하길 바란다. 

# Results

이전의 연구들보다 훨씬 더 향상된 성능을 보였다. 추가적으로, 여러 SR3 model을 이어서 몇 번의 upsampling을 통한 cascaded high-resolution image synthesis를 선보였는데, 한번에 high-resolution image를 만들어내는 것보다 더 적은 parameter로 좋은 성능을 낼 수 있다고 한다. 더 자세한 내용은 [SR3 paper](https://arxiv.org/abs/2104.07636)를 참조하길 바란다.

<img src="/assets/images/SR3_4.png" width="75%" height="75%">*Super-resolution task에 대한 결과.*
<img src="/assets/images/SR3_5.png" width="75%" height="75%">*여러 SR3 model을 이어 cascaded high-resolution image synthesis를 한 결과.*

# Conclusion

Bias is an important problem in all generative models.
SR3 is no different, and suffers from bias issues. While in
theory, our log-likelihood based objective is mode covering
(e.g., unlike some GAN-based objectives), we believe
it is likely our diffusion-based models drop modes. We observed
some evidence of mode dropping, the model consistently
generates nearly the same image output during sampling
(when conditioned on the same input). We also observed
the model to generate very continuous skin texture in
face super-resolution, dropping moles, pimples and piercings
found in the reference. SR3 should not be used for
any real world super-resolution tasks, until these biases are
thoroughly understood and mitigated.
In conclusion, SR3 is an approach to image super-resolution
via iterative refinement. SR3 can be used in a cascaded
fashion to generate high resolution super-resolution images, as well as unconditional samples when cascaded
with a unconditional model. We demonstrate SR3 on
face and natural image super-resolution at high resolution
and high magnification ratios. SR3 achieves a human fool rate
close to 50%, suggesting photo-realistic outputs.