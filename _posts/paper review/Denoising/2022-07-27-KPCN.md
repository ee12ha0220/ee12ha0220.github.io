---
title: 'Kernel-Predicting Convolutional Networks for Denoising Monte Carlo Renderings'
# image : ""
date: '2022-07-27'
categories: [Paper review, MC denoising]
# tags: [tag] 
author: saha
math: true
mermaid: true
pin : false
---

# Abstract

Regression-based algorithms have shown to be good at denoising Monte Carlo (MC) renderings by leveraging its inexpensive by-products (e.g., feature buffers).
However, when using higher-order models to handle complex cases, these techniques often overfit to noise in the input. For this reason, supervised learning methods have been proposed that train on a large collection of reference examples, but they use explicit filters that limit their denoising ability. To address these problems, we propose a novel, supervised
learning approach that allows the filtering kernel to be more complex and general by leveraging a deep convolutional neural network (CNN) architecture.
In one embodiment of our framework, the CNN directly predicts the final denoised pixel value as a highly non-linear combination of the input features.
In a second approach, we introduce a novel, kernel-prediction network which uses the CNN to estimate the local weighting kernels used to
compute each denoised pixel from its neighbors. We train and evaluate our networks on production data and observe improvements over state-of-the art
MC denoisers, showing that our methods generalize well to a variety of scenes. 
We conclude by analyzing various components of our architecture and identify areas of further research in deep learning for MC denoising.

# Introduction

## Monte Carlo denoising

보다 더 정확한 image를 생성하기 위해, 과거에 사용하던 REYES-style micropolygon architecture[Cook et al. 1987]에서 physically-based Monte Carlo (MC) path tracing [Kajiya 1986] 으로 많이 넘어오고 있다. 이 방법은 ray tracing을 사용하며, rendering equation의 적분을 쉽게 하기 위해 Monte Carlo integration을 사용한다(\ref{eq1}). 

---

$$
L_o(p,\omega_o) = \int_{\Omega^{+}} L_i(p, \omega_i)f_r(p,\omega_i,\omega_o)(n\cdot\omega_i)\mathbf{d}\omega_i \approx \frac{1}{N}\sum^{N}_{i=1}\frac{L_i(p,\omega_i)f_r(p,\omega_i,\omega_o)(n\cdot\omega_i)}{p(\omega_i)} \label{eq1} \tag{1}
$$ 

---

Monte Carlo integration은 unbiased estimator이기 때문에, sample의 개수($N$)이 많다는 전제 하에 ground truth로 수렴하게 된다. 하지만 많은 spp(sample per pixel)을 사용하면 그만큼 시간이 오래 걸리게 되는데, 그래서 적은 spp로 noisy image를 뽑아내고, 여기에 denoising을 통해 clean image를 얻어내는 **Monte Carlo denoising** 이 연구되고 있다. 

## Previous works

<!-- 이 논문 기준으로 sota method인 Kalantari et al.[2015] 에서는 MLP를 사용해서 denoising filter의 weight를 학습하는 방식을 채택했지만, 이는 적은 scene에 대해서만 학습되었고 고정된 filter 종류(joint bilateral or joint non-local means)만 사용할 수 있고, 쉽게 over-fitting이 되는 등 그 한계가 명확하다.

이 논문에서는 이를 극복하기 위해 **Convolutional Neural Network(CNN)**을 사용했다. CNN은 더 complex하고 general한 filtering kernel을 만들 수 있고, 한번 학습이 되면 inference time이 짧고, 여러 noise에 대해 더 robust하게 학습해 over-fitting을 완화시킬 수 있다. 

# Background

### Overview of MC denoising -->

Monte Carlo renderer에서 만들어진 image의 각 pixel 값 $\mathbf{x}_p \in\mathbb{R}^{3+D}$는 pixel당 RGB color을 나타내는 $c_p$, surface normal, depth, albedo, 그리고 이들의 variance정보를 담고 있는 D auxiliary features $\mathbf{f}_p$ 로 이루어져 있다. MC denoising에서 filtered color $\hat{c}_p$ 는 pixel $p$의 neighborhood $\mathcal{N}_p$에 속하는 per-pixel vector들인 $\mathbf{X}_p$와 CNN network를 이용해서 얻어지며, 이를 ground truth color $\bar{c}_p$ 와 가깝게 만드는 weight을 찾는 것을 목표로 한다(\ref{eq2}). 

---

$$
\hat{c}_p = g(\mathbf{X}_p;\hat{\theta}_p), \quad
\hat{\theta}_p = \underset{\theta}{\text{argmin }} \mathcal{l}(\bar{c}_p, \hat{c}_p) \label{eq2} \tag{2}
$$

---

하지만 이 과정에서 ground truth 값을 얻을 수 없기 때문에, 기존의 MC denoising 방법들은 $\mathcal{N}_p$에 속하는 다른 값들을 reference로 weight를 정했다(\ref{eq3}).

---

$$
\hat{c}_p = {\hat{\theta}}_p^\top \phi(\mathbf{x}_p), \quad \hat{\theta}_p = \underset{\theta}{\text{argmin}} \sum_{q\in\mathcal{N}(p)} (\mathbf{c}_q - {\theta}_p^\top \phi(\mathbf{x}_q))\omega({\mathbf{x}_p, \mathbf{x}_q}) \label{eq3} \tag{3}
$$

---

이때 $\omega({\mathbf{x}_p, \mathbf{x}_q})$ 는 일종의 regression kernel로, noise로 인해 심하게 변한 value들을 무시하게 해준다. 

점점 더 복잡한 $\phi$ 를 사용하는 방법들이 시도되었지만, 이는 특정 image에 over-fitting될 가능성이 높았기 때문에 그 한계를 보였다. 

그래서 Kalanari et al.[2015] 에서는 이를 해결하기 위해 supervised learning을 도입했는데, over-fitting을 막기 위해 전체 dataset을 $N$개의 patch들로 나눠서 그 평균을 이용해 학습을 했다(\ref{eq4}). 

---

$$
\hat{\theta} = \underset{\theta}{\text{argmin}} \frac{1}{N}\sum^{N}_{i=1}\mathcal{l}(\bar{c}_i, g(\mathbf{X}_i;\theta)) \label{eq4} \tag{4}
$$

---

하지만 이 경우에도 결국에는 고정된 filter을 사용했기 때문에, 표현에 한계가 존재했다. 더 flexible한 g를 사용하기 위해 이 논문에서는 **Convolutional Neural Network(CNN)**을 도입했다. 

# Deep convolutional denoising

## Network architecture
이 논문에서는 parameter의 개수를 적게 하기 위해서 fully connected layer을 사용하지 않고 오직 CNN만을 사용했다. 이는 over-fitting의 위험을 줄여줄 뿐만 아니라, training, inference speed를 모두 빠르게 해준다. 

각 layer사이의 activation function에는 ReLU가 사용되었고, 마지막에만 identity function이 사용되었다. 

## Reconstruction methods
Function g의 output에 따라 **direct-prediction(DPCN)** 과 **kernel-prediction(KPCN)** 으로 나뉠 수 있다. 

먼저 **DPCN**은 말 그대로 clean image자체를 얻는 것을 목표로 한다. 논문에 따르면 이 방법은 좋은 성능을 보였지만, optimization 과정에서 converge 속도가 엄청 느렸다고 한다. 

반면에 **KPCN**은 각 neighborhood에 맞는 특정한 kernel을 얻는 것을 목표로 한다. Kernel의 weight들은 마지막에 softmax function을 통해 normalize되는데, 이는 최종 clean image의 각 pixel의 값이 색의 범위를 벗어나지 않도록 해주고, gradient를 안정화시켜서 converge 속도 향상에 도움을 준다고 한다. 

## Diffuse/Specular decomposition

MC denoising을 거친 결과물은 over-blurring되는 경우가 많이 있는데, 이는 image에 존재하는 noise들의 원인과 특성이 다 제각기이기 때문에, denoising하는 데에 있어서 conflict를 일으키기 때문이다. 그래서 이 논문에서는 image를 diffuse, specular components으로 나눠서 이 현상을 줄이고자 했다. 

Diffuse components는 오차의 범위가 크지 않기 때문에 color preprocessing 없이도 좋은 결과를 보였다고 한다. 실제 실험에서는 noisy albedo 부분을 제거해줘서 irradiance 부분만 CNN에게 전달해줬다(\ref{eq5}). 

---

$$
\tilde{\mathbf{c}}_\text{diffuse} = {\mathbf{c}}_{\text{diffuse}} / (\mathbf{f}_\text{albedo} + \epsilon) \label{eq5} \tag{5}
$$

---

이때 $\epsilon$은 0으로 나누는 것을 막기 위한 상수이다. 

Specular components는 오차의 범위가 컸기 때문에, log scale로 만들어줘서 이를 완화시켰다(\ref{eq6}). 

---

$$
\tilde{\mathbf{c}}_\text{specular} = \log(1 + \mathbf{c}_{\text{specular}}) \label{eq6} \tag{6}
$$

---

Clean image로 restoration하는 과정에서는 아래의 역변환을 거쳤다(\ref{eq7}). 

---

$$
\hat{c} = (\mathbf{f}_\text{albedo} + \epsilon) * \hat{\mathbf{c}}_\text{diffuse} + \text{exp}(\hat{\mathbf{c}}_\text{specular})-1 \label{eq7} \tag{7}
$$

---

# Training