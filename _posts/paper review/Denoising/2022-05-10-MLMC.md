---
title: 'A Machine Learning Approach for Filtering Monte Carlo Noise'
# image : ""
date: '2022-05-10'
categories: [Paper review, MC denoising]
# tags: [tag] 
author: saha
math: true
mermaid: true
pin : false
---

# Abstract

The most successful approaches for filtering Monte Carlo noise use feature-based filters (e.g., cross-bilateral and cross non-local means filters) that exploit additional scene features such as world positions and shading normals. However, their main challenge is finding the optimal weights for each feature in the filter to reduce noise but preserve scene detail. In this paper, we observe there is a complex relationship between the noisy scene data and the ideal filter parameters, and propose to learn this relationship using a nonlinear regression model. To do this, we use a multilayer perceptron neural network and combine it with a matching filter during both training and testing. To use our framework, we first train it in an offline pro- cess on a set of noisy images of scenes with a variety of distributed effects. Then at run-time, the trained network can be used to drive the filter parameters for new scenes to produce filtered images that approximate the ground truth. We demonstrate that our trained net- work can generate filtered images in only a few seconds that are superior to previous approaches on a wide range of distributed effects such as depth of field, motion blur, area lighting, glossy reflections, and global illumination.

# Introduction

## Monte Carlo denoising using filters

초창기 Monte Carlo denoising은 대부분 filter을 이용해서 진행되었다. 그중에서 feature-based filter는 다양한 feature 정보를 guidance로 filter을 만드는 방법이고, 이는 뛰어난 성능을 보였다. 하지만 이러한 filter의 weight를 정하는 일은 시간도 오래 걸리고, 여러 assumption을 바탕으로 정해졌기 때문에 성능에도 한계가 있었다. 본 논문에서는 여러 feature과 해당하는 filter weight에는 어떠한 복잡한 관계가 있다고 말하며, 이를 machine learning을 통해 알아내고자 한다. 

# A new learning framework for MC filtering

본 논문의 목적은 적은 spp로 rendering된 noisy image가 주어졌을 때, 높은 spp로 rendering된 것과 유사한 noise-free image를 만들어내는 것을 목표로 한다. Filtered image $\hat{\mathbf{c}} = \left( \hat{c}_r, \hat{c}_g, \hat{c}_b \right)$는 다음과 같이 구할 수 있다(\ref{eq1}).

---

$$
\hat{\mathbf{c}}_i = \frac{\sum_{j \in \mathcal{N}(i)}d_{i,j}\bar{\mathbf{c}}_j}{\sum_{j \in \mathcal{N}(i)}d_{i,j}} \label{eq1} \tag{1}
$$

---

이때 $\mathcal{N}(i)$는 pixel $i$의 neighborhood를 의미하고, $d_{i,j}$는 $i$와 그 neighbor $j$ 사이의 filter weight를 의미한다. 이전의 연구들에서는 denoising 성능을 올리기 위해 **cross-bilateral filter**같은 특수한 filter을 사용했는데, 이 경우 $d_{i,j}$는 다음과 같이 정의된다(\ref{eq2}).

---

$$
d_{i,j} = \text(exp)\left[ -\frac{||\bar{\mathbf{p}}_i - \bar{\mathbf{p}}_j||^2}{2\alpha_i^2}\right] \times \text{exp}\left[ -\frac{D(\bar{\mathbf{c}}_i, \bar{\mathbf{c}}_j)}{2\beta_i^2} \right] \times \prod_{k=1}^K \text{exp}\left[ -\frac{D_k(\bar{\mathbf{f}}_{i,k}, \bar{\mathbf{f}}_{j,k})}{2\gamma_{k,i}^2} \right] \label{eq2} \tag{2}
$$

---

이때 $\bar{\mathbf{p}}_{i}$는 pixel 
$i$의 screen space position, $\bar{\mathbf{f}} _{i,k}$ 는 $k$번째 scene feature, $\alpha _i^2, \beta _i^2, \gamma _{k,i}^2$는 각각 $i$의 spatial, color, $k^\text{th}$ feature에 대한 variance, $D$, $D_k$는 color와 feature간의 거리를 측정하기 위한 특수한 함수들이다. 결국 $\alpha _i, \beta _i, \gamma _{k,i}$에 따라 $d _{i,j}$가 바뀌기 때문에, 이들의 값을 잘 예측하는 것이 관건이고, 이전의 feature-based filter을 사용하는 연구들은 모두 이 변수들의 값을 예측하는 방식에 차이가 있다. 

본 논문에서는 다음과 같이 이 filtering process를 더 general하게 접근한다(\ref{eq3}). 

---

$$
\hat{\mathbf{c}}_i = h(\bar{\mathbf{s}}_{\mathcal{N}(i)}, \mathbf{\theta}_i), \quad \text{where} \quad \bar{\mathbf{s}}_{\mathcal{N}(i)} = \underset{j \in \mathcal{N}(i)}{\bigcup} \bar{\mathbf{s}}_j \label{eq3} \tag{3}
$$

---

이때 $\bar{\mathbf{s}}_{\mathcal{N}(i)}$ 는 pixel $i$의 neighborhood에 있는 primary feature들의 모음이다. 예를 들어 앞서 소개한 cross-bilateral filter의 경우에는 $\mathbf{\theta}_i$가 $(\alpha, \beta, \gamma_1, ..., \gamma_K)$의 총 $K+2$개의 parameter을 갖고 있다고 생각할 수 있다. 궁극적으로, ground truth와 가장 오차가 적은 result를 만들어내는 optimal한 $\mathbf{\theta}$를 목표로 한다(\ref{eq4}).

---

$$
\mathbf{\theta}_i^* = \underset{\mathbf{\theta}_i}{\text{argmin }}E(h(\bar{\mathbf{s}}_{\mathcal{N}(i)}, \mathbf{\theta}_i), \mathbf{c}_i) \label{eq4} \tag{4}
$$

---

본 연구에서는 $\mathbf{\theta}_i^*$ 와 유사한 filter parameter $\hat{\mathbf{\theta}}_i$ 를 얻기 위해 secondary features $\mathbf{x}_i = (x_1, x_2, ..., x_N)$와 function $\mathcal{G}$를 이용한다(\ref{eq5}).

---

$$
\hat{\mathbf{\theta}}_i = \mathcal{G}(\mathbf{x}_i), \quad \mathcal{G}^* = \underset{\mathcal{G}}{\text{argmin }}E(h(\bar{\mathbf{s}}_{\mathcal{N}(i)}, \mathcal{G}(\mathbf{x}_i)), \mathbf{c}_i) \label{eq5} \tag{5}
$$

---

이때 function $\mathcal{G}$를 MLP를 이용해서 표현한다. 

<img src="/assets/images/MLMC_1.png" width="100%" height="100%">*사용된 MLP의 구조.*

## Primary features

본 논문에서는 screen position(2), color(3), world position(3), shading norma(3), texture values for the first and second intersections(각각 3), direct illumination visibility(1)의 총 18차원 7개의 primary feature을 사용한다. Primary feature들에 해당하는 distance function은 아래와 같다(\ref{eq6}, \ref{eq7}).

---

$$
D(\bar{\mathbf{c}}_i, \bar{\mathbf{c}}_j) = \frac{||\bar{\mathbf{c}}_i-\bar{\mathbf{c}}_j||^2}{\psi_i^2 + \psi_j^2 + \zeta} \label{eq6} \tag{6}
$$

---

이때 $\psi_i$, $\psi_j$는 pixel $i$, $j$의 color std이고, $\zeta = 10^{-10}$는 0으로 나누는 것을 방지하기 위한 작은 상수이다.  

---

$$
D_k(\bar{\mathbf{f}}_{i,k}, \bar{\mathbf{f}}_{j,k}) = \frac{||\bar{\mathbf{f}}_{i,k}-\bar{\mathbf{f}}_{j,k}||^2}{\max(\psi_{k,i}^2, \delta)} \label{eq7} \tag{7}
$$

---

이때 $\psi_{k,i}$는 pixel $i$의 $k$번째 feature의 std이고, $\delta = 10^{-4}$는 0으로 나누는 것을 방지하기 위한 작은 값이다. 

## Secondary features

각 pixel마다 primary feature에 기반한 secondary feature을 계산해서 사용한다. [본 논문](https://dl.acm.org/doi/10.1145/2766977)의 section 3.3에 아주 자세하게 설명이 되어 있으니 이를 참고하길 바란다. 

## Overall framework

<img src="/assets/images/MLMC_2.png" width="100%" height="100%">*전체 framework.*


# Training details

## Loss function
본 논문에서는 일반적인 MSE가 아니라 relative mean squared error(RelMSE)를 사용했다(\ref{eq8}).

---

$$
E_i = \frac{n}{2} \sum_{q \in \{r,g,b\}} \frac{(\hat{c}_{i,q} - c_{i,q})^2}{c_{i,q}^2 + \epsilon}
$$

---

$\epsilon = 0.01$은 0으로 나누는 것을 방지하기 위한 작은 상수이다. 이는 사람의 visual system이 어두운 부분에서의 오차에 더 민감하기 때문에 사용했다고 한다. 

더 자세한 사항은 [본 논문](https://dl.acm.org/doi/10.1145/2766977)을 참조하길 바란다. 
# Result

이전의 연구들에 비해 크게 발전된 결과를 얻을 수 있었다. 

<img src="/assets/images/MLMC_3.png" width="100%" height="100%">*이전의 연구들에 비해 크게 발전된 것을 볼 수 있다.*

더 자세한 사항은 [본 논문](https://dl.acm.org/doi/10.1145/2766977)을 참조하길 바란다. 

# Conclusion

We have presented a machine learning approach to reduce noise in
Monte Carlo (MC) rendered images. In order to model the complex
relationship between the ideal filter parameters and a set of features
extracted from the input noisy samples, we use a multilayer perceptron
(MLP) neural network as a nonlinear regression model. To
effectively train the network, we combine the MLP network with
a filter such that the standard MLP takes in a set of secondary features
extracted from a local neighborhood at each pixel and outputs
a set of filter parameters. These parameters and the noisy samples
are given as inputs to the filter to generate a filtered pixel that is
compared to the ground truth pixel during training. We train our
proposed system on a set of scenes with a variety of distributed
effects and then test it on different scenes containing motion blur,
depth of field, area lighting, glossy reflections, and global illumination.
Our results show that this simple approach demonstrates
visible improvement over existing state-of-the-art methods.