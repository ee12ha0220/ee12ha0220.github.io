---
title: 'Sample-based Monte Carlo Denoising using a Kernel-Splatting Network'
# image : ""
date: '2021-10-20'
categories: [Paper review, MC denoising]
# tags: [tag] 
author: saha
math: true
mermaid: true
pin : false
---

# Abstract

Denoising has proven to be useful to efficiently generate high-quality Monte Carlo renderings. Traditional pixel-based denoisers exploit summary statistics of a pixel’s sample distributions, which discards much of the samples’ information and limits their denoising power. On the other hand, sample based techniques tend to be slow and have difficulties handling general transport scenarios. We present the first convolutional network that can learn to denoise Monte Carlo renderings directly from the samples. Learning the mapping between samples and images creates new challenges for
the network architecture design: the order of the samples is arbitrary, and they should be treated in a permutation invariant manner. To address these challenges, we develop a novel kernel-predicting architecture that splats individual samples onto nearby pixels. Splatting is a natural solution to situations such as motion blur, depth-of-field and many light transport paths, where it is easier to predict which pixels a sample contributes to, rather than a gather approach that needs to figure out, for each pixel, which samples (or nearby pixels) are relevant. Compared to previous state-of-the-art methods, ours is robust to the severe noise of low-sample count images (e.g. 8 samples per pixel) and yields higher-quality results both visually and numerically. Our
approach retains the generality and efficiency of pixel-space methods while enjoying the expressiveness and accuracy of the more complex sample-based approaches.

# Introduction

[KPCN 논문](https://ee12ha0220.github.io/posts/KPCN/)에서 설명했듯이, Monte Carlo denoising은 적은 sample로 만들어진 noisy image를 이용해 clean image를 얻는 기법이다. 여기에는 크게 두가지의 종류가 있다고 하는데, rendering된 image를 이용하는 **pixel-based** method와, 실제로 image를 만들 때 사용된 sample에 대한 정보를 사용하는 **sample-based** method가 있다. 이전의 work에서는 대부분 pixel-based method를 사용했으며, noisy pixel color에 추가적으로 depth, normal, albedo등의 정보를 사용해서 denoisng을 한다. 본 논문, **SBMC** 에서는 sample-based method를 사용해 denoising을 수행하며, 이는 motion blur같은 특수한 상황에서 상당히 좋은 성능을 보인다. 

<img src="/assets/images/sbmc_1.png" width="90%" height="90%"> *Ground truth image와 denoised image를 비교해 봤을 때, sample-based method가 motion blur을 더 잘 표현한다.*

## Permutation invariance in Neural Networks

Sample에 대한 정보를 사용하면, neural network에 여러개의 input이 들어가게 된다. 실제 Monte carlo rendering에서 image를 만드는 과정을 생각해보면, input의 순서에 따라 network의 결과값이 달라지면 안된다. 

# Sample-based denoising network

SBMC는 sample-based method이기 때문에 pixel $(x,y)$ 에 대한 $s$개의 sample (noisy radiance $L_{xys}$, auxiliary features $f_{xys}$)를 input으로 받는다. Sample의 개수가 고정되어 있지 않기 때문에 기존의 single-pass feedforward neural network은 적합하지 않고, RNN 같은 경우에는 permutation-invariant하지 않기 때문에 적합하지 않다. 그래서 본 논문에서는 여러 per-sample non-linear processing들의 spatial information을 CNN을 통해 sharing하는 novel architecture을 소개한다. 

## Network architecture

Previous work [Bako et al. 2017; Vogels et al. 2018]과 마찬가지로, SBMC도 noisy image에 apply 될 수 있는 kernel을 만드는 것을 목표로 한다. 하지만 pixel단위가 아닌 sample단위이기 때문에, **각 sample이 근처에 있는 pixel에 얼마나 contribute 하는지**를 알아내는 것을 목표로 한다고 생각할 수 있다. 이 때문에 SBMC에서는 일반적인 gathering kernel이 아니라 **splatting kernel**, 즉 sample에 대한 정보를 주변 pixel에 splat하는 kernel을 사용한다(\ref{eq1}). 

---

$$
I_{uv} = \frac{\sum_{x,y,s}K_{xyuvs}L_{xys}}{\sum_{x,y,s}K_{xyuvs}}
\label{eq1} \tag{1}
$$

---

이때 $s$는 pixel $(x,y)$에 존재하는 각 sample, $K$는 predict하고자 하는 kernel, $I_{uv}$는 근처에 있는 pixel $(u,v)$의 denoised된 값을 의미한다. $K$는 [KPCN](https://ee12ha0220.github.io/posts/KPCN/)과 마찬가지로 $21\times21$의 크기로 사용한다. 

Permutation invariance를 만족시키기 위해, SBMC에서는 per-sample feature extraction과 spatial information sharing을 분리시킨다. 이때 **individual sample embedding**과 **per-pixel context feature** 라는 개념이 쓰인다. 

### 

<img src="/assets/images/sbmc_2.png" width="90%" height="90%">

<!-- We achieve this by splitting the
per-sample feature extraction and spatial information sharing into
alternating steps via the use of two key concepts: individual sample
embeddings and per-pixel context features. -->


# Deep convolutional denoising

## Network architecture
이 논문에서는 parameter의 개수를 적게 하기 위해서 fully connected layer을 사용하지 않고 오직 CNN만을 사용했다. 이는 over-fitting의 위험을 줄여줄 뿐만 아니라, training, inference speed를 모두 빠르게 해준다. 

각 layer사이의 activation function에는 ReLU가 사용되었고, 마지막에만 identity function이 사용되었다. 

## Reconstruction methods
Function g의 output에 따라 **direct-prediction(DPCN)** 과 **kernel-prediction(KPCN)** 으로 나뉠 수 있다. 

먼저 **DPCN**은 말 그대로 clean image자체를 얻는 것을 목표로 한다. 논문에 따르면 이 방법은 좋은 성능을 보였지만, optimization 과정에서 converge 속도가 엄청 느렸다고 한다. 

반면에 **KPCN**은 각 neighborhood에 맞는 특정한 kernel을 얻는 것을 목표로 한다. Kernel의 weight들은 마지막에 softmax function을 통해 normalize되는데, 이는 최종 clean image의 각 pixel의 값이 색의 범위를 벗어나지 않도록 해주고, gradient를 안정화시켜서 converge 속도 향상에 도움을 준다고 한다. 

## Diffuse/Specular decomposition

MC denoising을 거친 결과물은 over-blurring되는 경우가 많이 있는데, 이는 image에 존재하는 noise들의 원인과 특성이 다 제각기이기 때문에, denoising하는 데에 있어서 conflict를 일으키기 때문이다. 그래서 이 논문에서는 image를 diffuse, specular components으로 나눠서 이 현상을 줄이고자 했다. 

Diffuse components는 오차의 범위가 크지 않기 때문에 color preprocessing 없이도 좋은 결과를 보였다고 한다. 실제 실험에서는 noisy albedo 부분을 제거해줘서 irradiance 부분만 CNN에게 전달해줬다(\ref{eq5}). 

---

$$
\tilde{\mathbf{c}}_\text{diffuse} = {\mathbf{c}}_{\text{diffuse}} / (\mathbf{f}_\text{albedo} + \epsilon) \label{eq5} \tag{5}
$$

---

이때 $\epsilon$은 0으로 나누는 것을 막기 위한 상수이다. 

Specular components는 오차의 범위가 컸기 때문에, log scale로 만들어줘서 이를 완화시켰다(\ref{eq6}). 

---

$$
\tilde{\mathbf{c}}_\text{specular} = \log(1 + \mathbf{c}_{\text{specular}}) \label{eq6} \tag{6}
$$

---

Clean image로 restoration하는 과정에서는 아래의 역변환을 거쳤다(\ref{eq7}). 

---

$$
\hat{c} = (\mathbf{f}_\text{albedo} + \epsilon) * \hat{\mathbf{c}}_\text{diffuse} + \text{exp}(\hat{\mathbf{c}}_\text{specular})-1 \label{eq7} \tag{7}
$$

---

# Training

9개의 convolution layer을 사용했으며, 각 layer은 100개의 channel과 $5\times5$ 크기의 kernel을 갖고 있다. 마지막 output kernel의 크기는 $21\times21$ 로, 최종 layer의 channel 수는 $21^2$이 된다. Input data는 $1280\times1280$ 크기의 image로, diffuse color + variance(4), specular color + variance(4), diffuse color derivative(6), specular color derivative(6), normals + variance(4), normals derivative(6), albedo + variance(4), albedo derivative(6), depth + variance(2), depth derivative(2)로 총 44개의 channel이 있다. 앞서 설명했듯이 diffuse, specular로 나눠서 2개의 model을 학습하기 때문에, 각 model에는 34개의 channel이 input으로 들어가게 된다. 

# Result

Refer to [original paper](http://disneyresearch.s3.amazonaws.com/wp-content/uploads/20170630135237/Kernel-Predicting-Convolutional-Networks-for-Denoising-Monte-Carlo-Renderings-Paper33.pdf)