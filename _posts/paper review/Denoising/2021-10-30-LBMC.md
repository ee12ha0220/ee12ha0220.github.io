---
title: 'Neural Denoising with Layer Embeddings'
# image : ""
date: '2021-10-30'
categories: [Paper review, MC denoising]
# tags: [tag] 
author: saha
math: true
mermaid: true
pin : false
---

# Abstract

We propose a novel approach for denoising Monte Carlo path traced images, which uses data from individual samples rather than relying on pixel aggregates. Samples are partitioned into layers, which are filtered separately, giving the network more freedom to handle outliers and complex visibility. Finally the layers are composited front-to-back using alpha blending. The system is trained end-to-end, with learned layer partitioning, filter kernels, and compositing. We obtain similar image quality as recent state-of-the-art sample based denoisers at a fraction of the computational cost and memory requirements.

# Introduction

Monte Carlo denoising는 적은 spp로 만들어진 noisy image를 denoise하는 것을 목표로 한다. [KPCN](https://ee12ha0220.github.io/posts/KPCN/)에서는 이에 machine learning과 noisy image에 적용할 수 있는 kernel을 만든다는 아이디어를 제공했고, [SBMC](https://ee12ha0220.github.io/posts/SBMC/)에서는 noisy image만을 이용하는 것이 아니라 rendering에 사용되는 각 sample을 활용하는 per-sample denoiser에 대한 아이디어를 제공했다. 

Per-sample denoiser은 뛰어난 성능을 보이지만, computationally expensive하기 때문에 real-time rendering에 사용되기에 힘들다는 문제가 있다. 추가적으로 kernel을 각 sample에 적용하기 때문에, sample의 수가 많아지면 denoising task가 쉬워져야하는 것과는 역설적으로 consume하는 resource가 많아진다. 본 논문(LBMC)에서는 neural network를 사용해 각 sample에 대한 compact representation을 학습시켜 전반적인 computational cost를 줄이고자 한다. 

이를 위해 LBMC는 각 sample을 layer로 partition하는 것을 배우는 novel architecture을 사용한다. Kernel은 sample 단위가 아니라 만들어진 layer단위로 이루어지게 되고, 이는 [SBMC](https://ee12ha0220.github.io/posts/SBMC/)와 비슷한 유익을 누리게 해준다. 이 방법은 sample의 개수보다는 layer의 개수에 영향을 받기 때문에 더 효율적으로 denoising을 진행할 수 있고, 실제로 layer의 개수가 2개일 때도 sample-based denoiser의 이점을 모두 가질 수 있다고 한다. 

# Architecture

앞부분의 구조는 [SBMC](https://ee12ha0220.github.io/posts/SBMC/)와 비슷한 구조를 갖고 있고, 뒷부분에 layer embedding stage가 있다. SBMC와 비교했을 때 UNet을 이용해 input feature의 개수를 74개에서 20개로 줄인다. 전체적인 구조는 아래의 5개 stage로 나눌 수 있다. 

- **Sample reducer** : Input sample radiance, feature의 차원을 줄여 sample embedding을 만든다. 
- **U-net** : Sample embedding을 이용해 context feature을 만든다. 
- **Sample partitioner** : Sample embedding을 2개 이상의 layer에 splat해서 layer embedding을 만든다. Splatting weight은 sample embedding과 context feature, 그리고 FCN을 사용해서 만들어진다. 
- **Layer filtering** : Layer embedding, context features 그리고 FCN을 사용해 kernel을 만들어 각 layer에 적용시킨다. 
- **Compositing** : 각 layer에서 생성된 결과를 composite해서 최종적인 결과를 생성한다. 

Sample embedding과 context feature을 만드는 과정은 SBMC와 유사하기 때문에 설명을 생략하겠다. 

<img src="/assets/images/LBMC_1.png" width="100%" height="100%"> *LBMC model의 architecture*

## Per-layer processing

Fully connected network을 이용해 sample별 weight $w^l_{xys}$ 만들고, 이를 통해 sample embedding을 각 layer에 splat 해준다. 이때 sample당 weight의 합은 1이 된다. 각 layer마다 weight sum $w^l_{xy}$, layer occupancy $n^l_{xy}$(sample이 어느 layer에 속해 있는지에 대한 정보), weighted sum of radiance $L^l_{xy}$, weighted sum of embeddings $E^l_{xy}$를 track 해준다(\ref{eq1}). 

---

$$
\begin{align}
    &w^l_{xy} = \sum_s w^l_{xys} \\
    &n^l_{xy} = \sum_s \sum_{k=0}^{l-1}w^k_{xys} \\
    &L^l_{xy} = \sum_s w^l_{xys}L_{xys} \\
    &E^l_{xy} = \sum_s w^l_{xys}E_{xys} \label{eq1} \tag{1}
\end{align}
$$

---

Kernel이 만들어지면 $L, w, n$에 적용되어 새로운 값을 생성하게 된다(\ref{eq2}). 

---

$$
\begin{align}
    &\bar{L}^l_{xy} = L^l_{xy} * K^l_{xyuv} \\
    &\bar{w}^l_{xy} = w^l_{xy} * K^l_{xyuv} \\
    &\bar{n}^l_{xy} = n^l_{xy} * K^l_{xyuv} \label{eq2} \tag{2}
\end{align}
$$

---

## Compositing

각 Layer에서 나온 결과를 composite해서 최종 결과를 만든다. 먼저 radiance와 layer weight을 normalize 해주고, 이들을 이용해 최종 pixel color $o_{xy}$를 계산해준다(\ref{eq3}).

---

$$
\begin{align}
    &\hat{L}^l_{xy} = \frac{\bar{L}^l_xy}{\bar{n}^l_{xy}},\quad \alpha^l_{xy} = \frac{\bar{w}^l_xy}{\bar{n}^l_{xy}} \\
    &o_xy = \hat{L}^0_{xy} + \sum_{l=1}^{N} \hat{L}^l_{xy} \prod_{j=0}^{l-1}(1-\alpha^j_{xy}) \label{eq3} \tag{3}
\end{align}
$$

---

# Dataset and training

학습에는 4352장의 $256\times256$, 5 bounces, Russian Roulette disabled, 8spp rendered image를 사용했고 ground truth image는 4096spp rendered image를 사용했다. 

Symmetric mean absolute percentage error(SMAPE)라는 metric을 사용했는데, HDR image를 denoise하는 데 stable한 metric이라는 report가 있었다고 한다. Reference $\mathbf{r}$, denoised image $\mathbf{d}$에 대해 수식은 다음과 같다(\ref{eq4}). 

---

$$
SMAPE(\mathbf{r}, \mathbf{d}) = \frac{1}{3N}\sum_{p \in N} \sum_{c \in C} \frac{|\mathbf{d}_{p,c} - \mathbf{r}_{p,c}|}{|\mathbf{d}_{p,c}| + |\mathbf{r}_{p,c}| + \epsilon} \label{eq4} \tag{4}
$$

---

더 자세한 정보는 [LBMC 논문](https://research.nvidia.com/publication/2020-06_neural-denoising-layer-embeddings)을 참조하길 바란다. 


# Result

LBMC는 previous work와 비교했을 때 성능 면에서는 큰 차이를 보이지 않는다. 하지만 computational cost 측면에서는 훨씬 더 효율적인 모습을 보인다. 특히 SBMC와 유사한 **SampleSplat**와 비교해 보면 computational cost 측면에서 상당히 많이 향상된 것을 볼 수 있다. 더 자세한 설명은 [LBMC 논문](https://research.nvidia.com/publication/2020-06_neural-denoising-layer-embeddings)을 참조하길 바란다. 

<img src="/assets/images/LBMC_2.png" width="90%" height="90%">*성능 면에서는 previous work과 비슷한 모습을 보여준다.*
<img src="/assets/images/LBMC_3.png" width="90%" height="90%">*Computational cost부분에는 상당히 많은 improvement가 있었다.*

# Conclusion
We have presented a layer-based denoising algorithm that produces image quality comparable to per-sample denoising, both visually and in image quality metrics, while being almost as efficient as denoisers working on accumulated pixel values. We denoise 1080p images at interactive rates on contemporary GPUs.

We observe similar robustness against outlier samples, a smoother look, and better handling of out-of-focus regions as first shown by [SBMC]((https://groups.csail.mit.edu/graphics/rendernet/)). In general, it seems beneficial to give the network the flexibility to apply more than one kernel per pixel. In practice, we see most benefits already with two layers.

When comparing PIXELGATHER and SAMPLESPLAT in our evaluation, the differences are fairly subtle, and smaller than what we had anticipated. This may be an effect of our reduced input feature count (20 instead of 74 floats) compared to SBMC, and differences in training data and test set. In scenarios where runtime performance is critical, it remains an open question if it is worth the added cost of incorporating per-sample information in machine learning denoisers, both in terms of the additional bandwidth usage requirements and the added arithmetics of per-sample or per-layer kernels. Extreme firelies are less common in real-time rendering settings with short ray paths and smooth approximations of global illumination.

Still, we argue that a layered denoising architecture is a flexible, scalable tool to exploit per-sample data. Our architecture learns to partition samples into layers, learns unique filter kernels per layer and alpha composite the filtered layers, all trained end-to-end. We hope this research will inspire future progress in denoising for both offline and real-time rendering.

In future work, we hope to apply similar ideas to deep compositing workflows. We also want to extend the layer denoising approach to the temporal domain, by denoising sequences, similar to recent work [CKS∗ 17, VRM∗ 18, HMP∗ 20]. We believe a layered representation can be beneficial to more robustly handle disocclusion and ghosting effects.
