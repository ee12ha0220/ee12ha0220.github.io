---
title: 'Sample-based Monte Carlo Denoising using a Kernel-Splatting Network'
# image : ""
date: '2022-04-08'
categories: [Paper review, MC denoising]
# tags: [tag] 
author: saha
math: true
mermaid: true
pin : false
---

# Abstract

Denoising has proven to be useful to efficiently generate high-quality Monte Carlo renderings. Traditional pixel-based denoisers exploit summary statistics of a pixel’s sample distributions, which discards much of the samples’ information and limits their denoising power. On the other hand, sample based techniques tend to be slow and have difficulties handling general transport scenarios. We present the first convolutional network that can learn to denoise Monte Carlo renderings directly from the samples. Learning the mapping between samples and images creates new challenges for
the network architecture design: the order of the samples is arbitrary, and they should be treated in a permutation invariant manner. To address these challenges, we develop a novel kernel-predicting architecture that splats individual samples onto nearby pixels. Splatting is a natural solution to situations such as motion blur, depth-of-field and many light transport paths, where it is easier to predict which pixels a sample contributes to, rather than a gather approach that needs to figure out, for each pixel, which samples (or nearby pixels) are relevant. Compared to previous state-of-the-art methods, ours is robust to the severe noise of low-sample count images (e.g. 8 samples per pixel) and yields higher-quality results both visually and numerically. Our approach retains the generality and efficiency of pixel-space methods while enjoying the expressiveness and accuracy of the more complex sample-based approaches.

# Introduction

[KPCN 논문](https://ee12ha0220.github.io/posts/KPCN/)에서 설명했듯이, Monte Carlo denoising은 적은 sample로 만들어진 noisy image를 이용해 clean image를 얻는 기법이다. 여기에는 크게 두가지의 종류가 있다고 하는데, rendering된 image를 이용하는 **pixel-based** method와, 실제로 image를 만들 때 사용된 sample에 대한 정보를 사용하는 **sample-based** method가 있다. 이전의 work에서는 대부분 pixel-based method를 사용했으며, noisy pixel color에 추가적으로 depth, normal, albedo등의 정보를 사용해서 denoisng을 한다. 본 논문, **SBMC** 에서는 sample-based method를 사용해 denoising을 수행하며, 이는 motion blur같은 특수한 상황에서 상당히 좋은 성능을 보인다. 

<img src="/assets/images/SBMC_1.png" width="90%" height="90%"> *Ground truth image와 denoised image를 비교해 봤을 때, sample-based method가 motion blur을 더 잘 표현한다.*

## Permutation invariance in Neural Networks

Sample에 대한 정보를 사용하면, neural network에 여러개의 input이 들어가게 된다. 실제 Monte carlo rendering에서 image를 만드는 과정을 생각해보면, input의 순서에 따라 network의 결과값이 달라지면 안된다. 

# Sample-based denoising network

SBMC는 sample-based method이기 때문에 pixel $(x,y)$ 에 대한 $s$개의 sample (noisy radiance $L_{xys}$, auxiliary features $f_{xys}$)를 input으로 받는다. Sample의 개수가 고정되어 있지 않기 때문에 기존의 single-pass feedforward neural network은 적합하지 않고, RNN 같은 경우에는 permutation-invariant하지 않기 때문에 적합하지 않다. 그래서 본 논문에서는 여러 per-sample non-linear processing들의 spatial information을 CNN을 통해 sharing하는 novel architecture을 소개한다. 

Previous work [Bako et al. 2017; Vogels et al. 2018]과 마찬가지로, SBMC도 noisy image에 apply 될 수 있는 kernel을 만드는 것을 목표로 한다. 하지만 pixel단위가 아닌 sample단위이기 때문에, **각 sample이 근처에 있는 pixel에 얼마나 contribute 하는지**를 알아내는 것을 목표로 한다고 생각할 수 있다. 이 때문에 SBMC에서는 일반적인 gathering kernel이 아니라 **splatting kernel**, 즉 sample에 대한 정보를 주변 pixel에 splat하는 kernel을 사용한다(\ref{eq1}). 

---

$$
I_{uv} = \frac{\sum_{x,y,s}K_{xyuvs}L_{xys}}{\sum_{x,y,s}K_{xyuvs}}
\label{eq1} \tag{1}
$$

---

이때 $s$는 pixel $(x,y)$에 존재하는 각 sample, $K$는 predict하고자 하는 kernel, $I_{uv}$는 근처에 있는 pixel $(u,v)$의 denoised된 값을 의미한다. $K$는 [KPCN](https://ee12ha0220.github.io/posts/KPCN/)과 마찬가지로 $21\times21$의 크기로 사용한다. 

## Sample embeddings and context features

Permutation invariance를 만족시키기 위해, SBMC에서는 per-sample feature extraction과 spatial information sharing을 분리시킨다. 이때 **individual sample embedding**과 **per-pixel context feature** 라는 개념이 쓰인다. 

먼저 fully connected layer을 이용해 각 sample마다 embedding을 만든다. 이때 각 sample은 서로에게 영향을 주지 않기 때문에, sample의 순서에 영향을 받지 않는다. 즉, permutation invariance를 갖게된다(\ref{eq2}). 

---

$$
E^0_{xys} = \text{FC}(L_{xys},f_{xys};\theta^0_E) \label{eq2} \tag{2}
$$

---

그 후 각 sample들 사이의 정보 교환을 위해 $E^0$를 이용해 per-pixel context feature $C^0$를 계산해준다(\ref{eq3}).

---

$$
C^0_{xy} = \underset{s}{\text{reduce_mean}}(E^0_{xys}) \label{eq3} \tag{3}
$$

---

그냥 평균을 취하는 것이기 때문에, permutation invariance가 유지된다. 추가적으로 $C^0$는 sample의 개수와 상관없이 같은 차원을 갖기 때문에 CNN을 사용할 수 있게 된다. 

이렇게 만들어진 $C^0$는 U-Net을 통해 같은 차원의 또다른 context feature $C^1$으로 변환되고, 이는 sample embedding $E^0$과 함께 fully connected layer에 feed되어 새로운 sample embedding $E^1$을 생성한다(\ref{eq4}).

---

$$
C^1 = \text{UNet}(C^0;\theta^0_C) \quad E^1_{xys} = \text{FC}(E^0_{xys},C^1_{xy}; \theta^1_{E})
\label{eq4} \tag{4}
$$

---

이 과정을 3번정도 반복해서 만들어진 sample embedding이 kernel prediction에 사용되는데, 이는 자신에 대한 정보 뿐만 아니라 neighborhood의 정보도 담고 있기 때문에 coherent한 결과를 낼 수 있도록 해준다. 

## Per-sample splatting kernels

Splatting kernel은 앞서 생성한 sample embedding과 fully connected network을 이용해서 만들어진다(\ref{eq5}).

---

$$
K_{xyuvs} = \text{FC}(E^n_{xys}, C^n_{xy};\theta_K) \label{eq5} \tag{5}
$$

---

이때 $u,v$는 $x,y$의 neighbor pixel을 의미한다. 이때 gather kernel이 아니라 splatting kernel을 사용하는 이유는, sample을 기준으로 만든 embedding을 이용해 kernel을 만들기 때문에 sample의 view에서 작업을 수행하는 것이 permutation invariance를 유지하기 쉽기 때문이다. 더 자세한 내용은 아래 figure과 함께 설명되어 있다. 

<img src="/assets/images/SBMC_4.png" width="100%" height="100%">*앞서 kernel을 생성할 때 현재 pixel에 있는 sample embedding만을 사용하기 때문에, 이 상황처럼 a와 b의 index가 바뀌면 a에 b를 고려하며 학습된 잘못된 weight가 들어가게 된다. Splatting kernel을 사용할 경우 이를 방지할 수 있다.*

## Overall structure and algorithm

<img src="/assets/images/SBMC_2.png" width="90%" height="90%">*SBMC model의 전체적인 구조*

<img src="/assets/images/SBMC_3.png" width="90%" height="90%">*SBMC model의 algorithm*

# Dataset and training procedure

SBMC에서는 $128\times128$ 해상도의 rendered image 300,000장을 학습에 사용했고, 동일한 방식으로 1,000장을 rendering해서 validation에 사용했다. Ground truth image의 경우에는 4096 spp로 rendering된 image를 사용했다. 더 자세한 설명은 [SBMC 논문](https://groups.csail.mit.edu/graphics/rendernet/)을 참조하길 바란다. 

# Result

SBMC는 previous work와 비교했을 때 좋은 성능을 보여줬으며, 특히 motion blur이나 depth of field등 auxiliary buffer에 noise가 큰 경우에 특출나게 좋은 성능을 보여줬다. 더 자세한 설명은 [SBMC 논문](https://groups.csail.mit.edu/graphics/rendernet/)을 참조하길 바란다.

<img src="/assets/images/SBMC_5.png" width="90%" height="90%">*Depth of field 상황에서 KPCN보다 확연하게 뛰어난 성능을 보여준다.*


# Conclusion

We propose a new convolutional neural network for denoising Monte Carlo renderings. The key innovations that explain the suc- cess of our method are the use of samples rather than pixel statistics and splatting rather than gathering. For this, we introduce a new kernel-splatting architecture that is invariant to input permutations and accepts arbitrary numbers of samples. We show that our approach is robust to severe, heavy-tailed noise in low sample count settings and excels at rendering scenes with distributed effects such as depth-of-field, achieving significantly-reduced error on our extensive tests.

