---
title: "Denoising Diffusion Probabilistic Models"
# image : ""
date: '2023-01-14'
categories: [Paper review, Diffusion model]
tags: [tag] 
author: saha
math: true
mermaid: true
pin : false
---

# Abstract
We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models nat- urally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN. Our imple- mentation is available at https://github.com/hojonathanho/diffusion.

# Introduction
Diffusion model은 작은 noise를 iteratively하게 더하는 forward process가 주어졌을 때, 그 backward process를 학습하고자 하는 model이다. Denoising Diffusion Probabilistic Models (DDPM)은 diffusion model의 일종으로, forward process를 Gaussian noise로 정의한다. 

<img src="/assets/images/DDPM_framework.png" width="100%" height="100%">*DDPM의 framework. Forward process ($q$)*

# Proposed method
## Forward process
DDPM에서 forward process는 다음과 같은 Markov chain으로 정의된다 : 

---

$$
q(\mathbf{x}_t|\mathbf{x}_{t-1}) = \mathcal{N}(\mathbf{x}_t;\sqrt{\alpha_t}\mathbf{x}_{t-1}, (1-\alpha_t)\mathbf{I})
$$

---

이때 $\alpha_t$는 pre-defined noise schedule로, distribution의 급격한 변화를 방지하기 위해 1과 가까운 값으로 설정된다. Forward process에 reparameterization trick를 적용하면 $\mathbf{x}_t$를 $\mathbf{x}_0$를 이용해서 표현할 수 있다 :

---

$$
\begin{align}
\mathbf{x}_t 
&= \sqrt{\alpha_t}\mathbf{x}_{t-1} + \sqrt{1-\alpha_t}\epsilon \\
&= \sqrt{\alpha_t\alpha_{t-1}}\mathbf{x}_{t-2} + \sqrt{1-\alpha_t\alpha_{t-1}}\epsilon\\
&= \ldots \\
&= \sqrt{\bar{\alpha}_t}\mathbf{x}_0 + \sqrt{1-\bar{\alpha}_t}\epsilon \\
q(\mathbf{x}_t|\mathbf{x}_0) &= \mathcal{N}(\mathbf{x}_t;\sqrt{\bar{\alpha}_t}\mathbf{x}_0, (1-\bar{\alpha}_t)\mathbf{I})
\end{align}
$$

---

이때 $\epsilon \sim \mathcal{N}(0,I)$이고, $\bar{\alpha} _t = \prod _{i=1}^t\alpha_i$이다. 즉, $\mathbf{x}_0$와 $t$가 주어지면 쉽게 $\mathbf{x}_t$를 계산할 수 있다.

## Inverse forward process
Inverse forward process는 다음과 같이 정의된다 : 

---

$$
q(\mathbf{x}_{t-1}|\mathbf{x}_{t},\mathbf{x}_{0}) = \mathcal{N}(\mathbf{x}_{t-1}; \tilde{\mu}(\mathbf{x_t}, \mathbf{x}_0), \tilde{\sigma}^2(t)\mathbf{I})
$$

---

이는 다음과 같이 유도할 수 있다 :

---

$$
\begin{align}
q(\mathbf{x}_{t-1}|\mathbf{x}_{t},\mathbf{x}_{0}) &= q(\mathbf{x}_{t}|\mathbf{x}_{t-1},\mathbf{x}_{0})\frac{q(\mathbf{x}_{t-1}|\mathbf{x}_{0})}{q(\mathbf{x}_{t}|\mathbf{x}_{0})} \\
& \propto \text{exp}\left( -\frac{1}{2}\left(\frac{(\mathbf{x}_{t} - \sqrt{\alpha_t}\mathbf{x}_{t-1})^2}{\beta_t} + \frac{(\mathbf{x}_{t-1} - \sqrt{\bar{\alpha}_{t-1}}\mathbf{x}_{0})^2}{1-\bar{\alpha}_{t-1}} - \frac{(\mathbf{x}_{t} - \sqrt{\bar{\alpha}_t}\mathbf{x}_{0})^2}{1-\bar{\alpha}_t} \right) \right) \\
&= \text{exp}\left( -\frac{1}{2} \left( (\frac{\alpha_t}{\beta_t} + \frac{1}{1-\bar{\alpha}_{t-1}}) \mathbf{x}^2_{t-1} -(\frac{2\sqrt{\alpha_t}}{\beta_t}\mathbf{x}_t + \frac{2\sqrt{\bar{\alpha}_{t-1}}}{1-\bar{\alpha}_{t-1}} \mathbf{x}_0)\mathbf{x}_{t-1} + C(\mathbf{x}_t, \mathbf{x}_0) \right) \right) \\ \\
\tilde{\mu}(\mathbf{x}_t, \mathbf{x}_0) &= \frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}\mathbf{x}_t + \frac{\sqrt{\bar{\alpha}_{t-1}}(1-\alpha_t)}{1-\bar{\alpha}_t}\mathbf{x}_0 = \frac{1}{\sqrt{\alpha_t}}\left( \mathbf{x}_t - \frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}}\epsilon_t \right) \\
\tilde{\sigma}^2(t) &= \frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t} (1-\alpha_t)
\end{align}
$$

---

## Backward process
DDPM에서 backward process는 다음과 같이 정의된다 : 

---

$$
p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t) = \mathcal{N}(\mathbf{x}_{t-1};\mu_\theta(\mathbf{x}_t, t), \sigma^2_\theta(\mathbf{x}_t, t))
$$

---

Mean($\mu_\theta$)과 variance($\sigma^2_\theta$)를 학습하기 위해 backward process를 inverse forward process에 근사하게 된다 : 

---

$$
\mu_\theta(\mathbf{x}_t, t) = \frac{1}{\sqrt{\alpha_t}}\left( \mathbf{x}_t - \frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}}\epsilon_\theta(\mathbf{x}_t, t) \right), \,\sigma_\theta(\mathbf{x}_t, t) = \tilde{\sigma}(t)
$$

---

## Training process
Backward process를 보면 $\epsilon_\theta(\mathbf{x}_t,t)$만 학습하면 된다는 것을 알 수 있다. 즉, DDPM의 loss function은 다음과 같이 쓸 수 있다 : 

---

$$
\mathcal{L}_\text{DDPM} = \Vert \epsilon_t - \epsilon_\theta(\mathbf{x}_t,t) \Vert^2_2 = \Vert \epsilon_t - \epsilon_\theta(\sqrt{\bar{\alpha}_t}\mathbf{x}_0 + \sqrt{1-\bar{\alpha}_t}\epsilon_t,t) \Vert^2_2
$$

---

학습 과정의 각 step마다 $t \in [1;T]$를 random하게 골라서 학습하게 된다. 

## Sampling process

학습된 backward process를 이용하면 $\mathbf{x}_T \sim \mathcal{N}(0,I)$부터 시작해서 $\mathbf{x}_0 \sim p(\mathbf{x})$까지 sampling 할 수 있다 : 

---

$$
\begin{align}
\text{for t} &\in [T,\ldots,1]\\
\mathbf{x}_{t-1} &=  \mu_\theta(\mathbf{x}_t,t)+\sigma_\theta(\mathbf{x}_t,t)\epsilon\\
&= \frac{1}{\sqrt{\alpha_t}}\left( \mathbf{x}_t - \frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}}\epsilon_\theta(\mathbf{x}_t, t) \right) + \sigma_t\epsilon
\end{align}
$$

---