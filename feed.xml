<feed xmlns="http://www.w3.org/2005/Atom"> <id>https://ee12ha0220.github.io/</id><title>Saha's Blog</title><subtitle>A minimal, responsive, and powerful Jekyll theme for presenting professional writing.</subtitle> <updated>2023-03-14T17:20:15+09:00</updated> <author> <name>Seeha Lee</name> <uri>https://ee12ha0220.github.io/</uri> </author><link rel="self" type="application/atom+xml" href="https://ee12ha0220.github.io/feed.xml"/><link rel="alternate" type="text/html" hreflang="en" href="https://ee12ha0220.github.io/"/> <generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator> <rights> Â© 2023 Seeha Lee </rights> <icon>/assets/img/favicons/favicon.ico</icon> <logo>/assets/img/favicons/favicon-96x96.png</logo> <entry><title>Denoising Diffusion Probabilistic Models</title><link href="https://ee12ha0220.github.io/posts/DDPM/" rel="alternate" type="text/html" title="Denoising Diffusion Probabilistic Models" /><published>2023-01-14T00:00:00+09:00</published> <updated>2023-03-14T17:19:49+09:00</updated> <id>https://ee12ha0220.github.io/posts/DDPM/</id> <content src="https://ee12ha0220.github.io/posts/DDPM/" /> <author> <name>saha</name> </author> <category term="Paper review" /> <category term="Diffusion model" /> <summary> Abstract We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics... </summary> </entry> <entry><title>DENOISING DIFFUSION IMPLICIT MODELS</title><link href="https://ee12ha0220.github.io/posts/DDIM/" rel="alternate" type="text/html" title="DENOISING DIFFUSION IMPLICIT MODELS" /><published>2022-08-23T00:00:00+09:00</published> <updated>2022-09-27T17:22:25+09:00</updated> <id>https://ee12ha0220.github.io/posts/DDIM/</id> <content src="https://ee12ha0220.github.io/posts/DDIM/" /> <author> <name>saha</name> </author> <category term="Paper review" /> <category term="Image synthesis" /> <summary> Abstract Denoising diffusion probabilistic models (DDPMs) have achieved high quality image generation without adversarial training, yet they require simulating a Markov chain for many steps in order to produce a sample. To accelerate sampling, we present denoising diffusion implicit models (DDIMs), a more efficient class of iterative implicit probabilistic models with the same training procedur... </summary> </entry> <entry><title>Palette: Image-to-Image Diffusion Models</title><link href="https://ee12ha0220.github.io/posts/Palette/" rel="alternate" type="text/html" title="Palette: Image-to-Image Diffusion Models" /><published>2022-08-18T00:00:00+09:00</published> <updated>2022-08-18T00:00:00+09:00</updated> <id>https://ee12ha0220.github.io/posts/Palette/</id> <content src="https://ee12ha0220.github.io/posts/Palette/" /> <author> <name>saha</name> </author> <category term="Paper review" /> <category term="Image synthesis" /> <summary> Abstract This paper develops a unified framework for image-to-image translation based on conditional diffusion models and evaluates this framework on four challenging image-to-image translation tasks, namely colorization, inpainting, uncropping, and JPEG restoration. Our simple implementation of image-to-image diffusion models outperforms strong GAN and regression baselines on all tasks, witho... </summary> </entry> <entry><title>Image Super-Resolution via Iterative Refinement</title><link href="https://ee12ha0220.github.io/posts/SR3/" rel="alternate" type="text/html" title="Image Super-Resolution via Iterative Refinement" /><published>2022-08-13T00:00:00+09:00</published> <updated>2022-08-13T00:00:00+09:00</updated> <id>https://ee12ha0220.github.io/posts/SR3/</id> <content src="https://ee12ha0220.github.io/posts/SR3/" /> <author> <name>saha</name> </author> <category term="Paper review" /> <category term="Image synthesis" /> <summary> Abstract We present SR3, an approach to image Super-Resolution via Repeated Refinement. SR3 adapts denoising diffusion probabilistic models [17, 48] to conditional image generation and performs super-resolution through a stochastic iterative denoising process. Output generation starts with pure Gaussian noise and iteratively refines the noisy output using a U-Net model trained on denoising at ... </summary> </entry> <entry><title>Generative Modeling by Estimating Gradients of the Data Distribution</title><link href="https://ee12ha0220.github.io/posts/SMLD/" rel="alternate" type="text/html" title="Generative Modeling by Estimating Gradients of the Data Distribution" /><published>2022-08-10T00:00:00+09:00</published> <updated>2023-01-10T19:15:04+09:00</updated> <id>https://ee12ha0220.github.io/posts/SMLD/</id> <content src="https://ee12ha0220.github.io/posts/SMLD/" /> <author> <name>saha</name> </author> <category term="Paper review" /> <category term="Image synthesis" /> <summary> Abstract We introduce a new generative model where samples are produced via Langevin dynamics using gradients of the data distribution estimated with score matching. Because gradients can be ill-defined and hard to estimate when the data resides on low-dimensional manifolds, we perturb the data with different levels of Gaussian noise, and jointly estimate the corresponding scores, i.e., the ve... </summary> </entry> </feed>
