<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="NeRF−−: Neural Radiance Fields Without Known Camera Parameters" /><meta name="author" content="saha" /><meta property="og:locale" content="en" /><meta name="description" content="Abstract" /><meta property="og:description" content="Abstract" /><link rel="canonical" href="https://ee12ha0220.github.io/posts/NeRFmm/" /><meta property="og:url" content="https://ee12ha0220.github.io/posts/NeRFmm/" /><meta property="og:site_name" content="Saha’s Blog" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-01-23T00:00:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="NeRF−−: Neural Radiance Fields Without Known Camera Parameters" /><meta name="twitter:site" content="@twitter_username" /><meta name="twitter:creator" content="@saha" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"saha","url":"https://github.com/ee12ha0220/"},"dateModified":"2022-08-26T13:45:06+09:00","datePublished":"2022-01-23T00:00:00+09:00","description":"Abstract","headline":"NeRF−−: Neural Radiance Fields Without Known Camera Parameters","mainEntityOfPage":{"@type":"WebPage","@id":"https://ee12ha0220.github.io/posts/NeRFmm/"},"url":"https://ee12ha0220.github.io/posts/NeRFmm/"}</script><title>NeRF−−: Neural Radiance Fields Without Known Camera Parameters | Saha's Blog</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Saha's Blog"><meta name="application-name" content="Saha's Blog"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get MODE_ATTR() { return "data-mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener("change", () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } } /* ModeToggle */ const toggle = new ModeToggle(); function flipMode() { if (toggle.hasMode) { if (toggle.isSysDarkPrefer) { if (toggle.isLightMode) { toggle.clearMode(); } else { toggle.setLight(); } } else { if (toggle.isDarkMode) { toggle.clearMode(); } else { toggle.setDark(); } } } else { if (toggle.isSysDarkPrefer) { toggle.setLight(); } else { toggle.setDark(); } } toggle.notify(); } /* flipMode() */ </script><body data-spy="scroll" data-target="#toc" data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" class="mx-auto"> <img src="/assets/images/avatar_2.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Saha's Blog</a></div><div class="site-subtitle font-italic">공부한 것들을 까먹지 말자</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/ee12ha0220" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['ee12ha0220','kaist.ac.kr'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper"><div id="topbar" class="container d-flex align-items-center justify-content-between h-100 pl-3 pr-3 pl-md-4 pr-md-4"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>NeRF−−: Neural Radiance Fields Without Known Camera Parameters</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper" class="d-flex justify-content-center"><div id="main" class="container pl-xl-4 pr-xl-4"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pr-xl-4"><div class="post pl-1 pr-1 pl-md-2 pr-md-2"><h1 data-toc-skip>NeRF−−: Neural Radiance Fields Without Known Camera Parameters</h1><div class="post-meta text-muted"> <span> Posted <em class="" data-ts="1642863600" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Jan 23, 2022 </em> </span><div class="d-flex justify-content-between"> <span> By <em> <a href="https://github.com/ee12ha0220/">saha</a> </em> </span><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="1210 words"> <em>6 min</em> read</span></div></div></div><div class="post-content"><h1 id="abstract">Abstract</h1><p>This paper tackles the problem of novel view synthesis (NVS) from 2D images without known camera poses or intrinsics. Among various NVS techniques, Neural Radiance Field (NeRF) has recently gained popularity due to its remarkable synthesis quality. Existing NeRF-based approaches assume that the camera parameters associated with each input image are either directly accessible at training, or can be accurately estimated with conventional techniques based on correspondences such as Structure-from-Motion. In this work, we propose an end-to-end framework, termed NeRF−−, for training NeRF models given only RGB images, without pre-computed camera parameters. Specifically, we show that the camera parameters, including both intrinsics and extrinsics, can be automatically discovered via joint optimisation during the training of the NeRF model. On the standard LLFF benchmark, our model achieves novel view synthesis results on par with the baseline trained with COLMAP pre-computed camera parameters. We also conduct extensive analyses to understand the model behaviour under different camera trajectories, and show that in scenarios where COLMAP fails, our model still produces robust results.</p><h1 id="introduction">Introduction</h1><p>NeRF는 NVS에 뛰어난 성능을 보이지만, input image들의 camera pose, intrinsic을 알아야 model을 학습할 수 있다는 단점이 있다. Synthetic data에서는 이것이 큰 문제가 되지 않지만, 실제 카메라로 찍힌 real data에서는 정확한 pose와 intrinsic을 알아내는 것이 어렵다. NeRF에서는 structure-from-motion에 기반한 SFM colmap을 사용해서 이를 구했지만, 이는 100% 정확한 값은 아니었다. 본 논문(NeRF–)에서는 camera pose와 intrinsic을 모르는 상태에서도 학습 가능한 NeRF model을 제시했으며, camera parameter은 학습 과정에서 joint optimization을 통해 얻어진다고 한다.</p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 90% 90%'%3E%3C/svg%3E" data-src="/assets/images/NeRFmm_1.png" width="90%" height="90%" data-proofer-ignore><em>대략적인 학습 과정. Camera extrinsics(pose)와 intrinsics는 NeRF model과 함께 학습된다.</em></p><h1 id="background">Background</h1><p>NeRF–는 NeRF를 기반으로 만들어졌기 때문에, <a href="https://ee12ha0220.github.io/posts/NeRF/">NeRF</a>에 대한 내용을 확인하는 것을 추천한다.</p><h1 id="nerf-model">NeRF– model</h1><p>NeRF–는 camera parameters들도 학습을 시켜야 하기 때문에, 다음과 같은 loss function을 사용한다(\ref{eq1}).</p><hr /> \[\Theta^\star, \Pi^\star = \underset{\Theta, \Pi}{\text{argmin}}\,\mathcal{L}(\hat{\mathcal{I}}, \hat{\Pi}|\mathcal{I}) \label{eq1} \tag{1}\]<hr /><p>이때 $\mathcal{I}$는 RGB image, $\Theta$는 NeRF model의 weight, $\Pi$는 camera parameters를 의미한다.</p><h2 id="camera-parameters"><span class="mr-2">Camera parameters</span><a href="#camera-parameters" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>먼저 camera intrinsics는 다음과 같이 정의된다(\ref{eq2}).</p><hr /> \[K = \begin{pmatrix} f_x &amp; 0 &amp; c_x \\ 0 &amp; f_y &amp; c_y \\ 0 &amp; 0 &amp; 1 \end{pmatrix} \label{eq2} \tag{2}\]<hr /><p>이때 $f_x$, $f_y$는 focal length, $c_x$, $c_y$는 principle point이다. 학습 과정에서 $c_x$, $c_y$는 각각 $W/2$, $H/2$로 고정되었다.</p><p>Camera extrinsics(pose)는 다음과 같이 정의된다(\ref{eq3}).</p><hr /> \[\mathbf{R} = \mathbf{I} + \frac{sin(\alpha)}{\alpha} \mathbf{\phi}^{\wedge} + \frac{1 - cos(\alpha)}{\alpha ^2} (\mathbf{\phi}^{\wedge})^2 \label{eq3}\tag{3}\]<hr /><p>이는 axis-angle representation으로, $\mathbf{\phi} := \alpha\mathbf{\omega}$, $\mathbf{\phi} \in \mathbb{R}^3$는 rotation axis $\mathbf{\omega}$와 rotation angle $\alpha$의 곱이다. Skew operator $(\cdot)^\wedge$ 는 $\mathbf{\phi}$를 skew matrix으로 바꿔준다(\ref{eq4}).</p><hr /> \[\phi^{\wedge} = \begin{pmatrix} \phi_0 \\ \phi_1 \\ \phi_2 \end{pmatrix}^{\wedge} = \begin{pmatrix} 0 &amp; -\phi_2 &amp; \phi_1 \\ \phi_2 &amp; 0 &amp; -\phi_0 \\ -\phi_1 &amp; \phi_0 &amp; 0 \end{pmatrix} \label{eq4} \tag{4}\]<hr /><h2 id="joint-optimization-of-nerf-and-camera-parameters"><span class="mr-2">Joint optimization of NeRF and Camera Parameters</span><a href="#joint-optimization-of-nerf-and-camera-parameters" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>NeRF와 마찬가지로 각 training image $I_i$에 대해, 무작위로 $M$개의 pixel $(p_{i,m})_ {m=1}^M$을 선택해서, 각 pixel에 ray $\hat{\mathbf{r}}_{i,m}(h)$을 쏜다. Ray는 다음과 같이 정의된다(\ref{eq5}).</p><hr /> \[\begin{align} &amp;\hat{\mathbf{r}}_{i,m}(h) = \hat{\mathbf{t}}_i + h\hat{\mathbf{d}}_{i,m} \\ &amp;\hat{\mathbf{d}}_{i,m} = \hat{\mathbf{R}}_i\begin{pmatrix} (u-W/2)/\hat{f}_x \\ -(v-H/2)/\hat{f}_y \\ -1 \end{pmatrix} \end{align} \label{eq5} \tag{5}\]<hr /><p>이후 과정은 NeRF와 동일하며, NeRF model과 함께 $\hat{pi}_i = (\hat{f}_x, \hat{f}_y, \hat{\mathbf{\phi}}_i, \hat{\mathbf{t}}_i)$를 학습한다.</p><h2 id="refinement-of-camera-parameters"><span class="mr-2">Refinement of Camera Parameters</span><a href="#refinement-of-camera-parameters" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>NeRF–의 저자들에 따르면 camera parameter들은 sub-optimal에 빠질 가능성이 크다고 한다. 그렇기 때문에 initialization이 중요한데, NeRF– model을 조금 학습시킨 뒤 NeRF부분의 parameter은 다시 초기화하고, camera parameter부분은 그대로 유지하는 방법의 refinement를 사용한다고 한다.</p><h2 id="overall-framework"><span class="mr-2">Overall framework</span><a href="#overall-framework" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 90% 90%'%3E%3C/svg%3E" data-src="/assets/images/NeRFmm_2.png" width="90%" height="90%" data-proofer-ignore><em>NeRF–의 전체 framework.</em></p><h1 id="training-details">Training details</h1><p>NeRF와 비슷한 dataset을 사용했으며, evaluation metric또한 NeRF와 동일한 PSNR, SSIM, LPIPS를 사용했다. 더 자세한 사항은 <a href="https://arxiv.org/abs/2102.07064">NeRF– paper</a>을 참조하길 바란다.</p><h1 id="result">Result</h1><p>먼저 SFM colmap이 잘 작동하는 scene에 대해서는 거의 유사한 결과를 보였다. 하지만 colmap에서는 pose와 intrinsic을 알아내지 못해서 NeRF에서는 NVS에 실패했지만, NeRF–에서는 효과적으로 이를 알아내어 NVS에 성공한 경우가 있었다. 더 자세한 사항은 <a href="https://arxiv.org/abs/2102.07064">NeRF– paper</a>을 참조하길 바란다.</p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 90% 90%'%3E%3C/svg%3E" data-src="/assets/images/NeRFmm_3.png" width="90%" height="90%" data-proofer-ignore><em>SFM colmap이 잘 작동하는 scene에서는 거의 유사한 결과를 보인다.</em></p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 90% 90%'%3E%3C/svg%3E" data-src="/assets/images/NeRFmm_4.png" width="90%" height="90%" data-proofer-ignore><em>Rotation-dominant sequence에서는 NeRF에서 NVS에 실패한 반면, NeRF–에서는 성공한 것을 확인할 수 있다.</em></p><h1 id="conclusion">Conclusion</h1><p>In this work, we present an end-to-end NeRF-based pipeline, called NeRF−−, for novel view synthesis from sparse input views, which does not require any information about the camera parameters for training. Specifically, our model jointly optimise the camera parameters for each input image while simultaneously training the NeRF model. This eliminates the need of pre-computing the camera parameters using potentially erroneous SfM methods (e.g. COLMAP) and still achieves comparable view synthesis results as the COLMAPbased NeRF baseline.We present extensive experimental results and demonstrate the effectiveness of this joint optimisation framework under different camera trajectory patterns, even when the baseline COLMAP fails to estimate the camera parameters. Despite its current limitations discussed above, our proposed joint optimisation pipeline has demonstrated promising results on this highly challenging task, which presents a step forward towards novel view synthesis on more general scenes with an end-to-end approach.</p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/paper-review/'>Paper review</a>, <a href='/categories/nvs/'>NVS</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=NeRF%E2%88%92%E2%88%92%3A+Neural+Radiance+Fields+Without+Known+Camera+Parameters+-+Saha%27s+Blog&url=https%3A%2F%2Fee12ha0220.github.io%2Fposts%2FNeRFmm%2F" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=NeRF%E2%88%92%E2%88%92%3A+Neural+Radiance+Fields+Without+Known+Camera+Parameters+-+Saha%27s+Blog&u=https%3A%2F%2Fee12ha0220.github.io%2Fposts%2FNeRFmm%2F" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2Fee12ha0220.github.io%2Fposts%2FNeRFmm%2F&text=NeRF%E2%88%92%E2%88%92%3A+Neural+Radiance+Fields+Without+Known+Camera+Parameters+-+Saha%27s+Blog" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" data-title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/DDPM/">Denoising Diffusion Probabilistic Models</a><li><a href="/posts/SMLD/">Generative Modeling by Estimating Gradients of the Data Distribution</a><li><a href="/posts/DDIM/">DENOISING DIFFUSION IMPLICIT MODELS</a><li><a href="/posts/fn/">각종 코드 정리</a><li><a href="/posts/MLMC/">A Machine Learning Approach for Filtering Monte Carlo Noise</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/tag/">tag</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 pl-3 pr-3 pr-xl-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/NeRF/"><div class="card-body"> <em class="small" data-ts="1641308400" data-df="ll" > Jan 5, 2022 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis</h3><div class="text-muted small"><p> Abstract We present a method that achieves state-of-the-art results for synthesizing novel views of complex scenes by optimizing an underlying continuous volumetric scene function using a sparse s...</p></div></div></a></div><div class="card"> <a href="/posts/NeRFpp/"><div class="card-body"> <em class="small" data-ts="1641999600" data-df="ll" > Jan 13, 2022 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>NERF++: ANALYZING AND IMPROVING NEURAL RADIANCE FIELDS</h3><div class="text-muted small"><p> Abstract Neural Radiance Fields (NeRF) achieve impressive view synthesis results for a variety of capture settings, including 360◦ capture of bounded scenes and forward-facing capture of bounded a...</p></div></div></a></div><div class="card"> <a href="/posts/uORF/"><div class="card-body"> <em class="small" data-ts="1643814000" data-df="ll" > Feb 3, 2022 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Unsupervised Discovery of Object Radiance Fields</h3><div class="text-muted small"><p> Introduction Object-centric representation is a constant topic of interest in computer vision and machine learning. Such representation should bear three characteristics: Should be ...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/post2/" class="btn btn-outline-primary" prompt="Older"><p>Github Blog에 코드 넣기</p></a> <a href="/posts/OCLSA/" class="btn btn-outline-primary" prompt="Newer"><p>Object-Centric Learning with Slot Attention</p></a></div></div></div><footer class="row pl-3 pr-3"><div class="col-12 d-flex justify-content-between align-items-center text-muted pl-0 pr-0"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://twitter.com/username">Seeha Lee</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/tag/">tag</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><script src="https://cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js"></script> <script> $(function() { function updateMermaid(event) { if (event.source === window && event.data && event.data.direction === ModeToggle.ID) { const mode = event.data.message; if (typeof mermaid === "undefined") { return; } let expectedTheme = (mode === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* Re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } let initTheme = "default"; if ($("html[data-mode=dark]").length > 0 || ($("html[data-mode]").length == 0 && window.matchMedia("(prefers-color-scheme: dark)").matches ) ) { initTheme = "dark"; } let mermaidConf = { theme: initTheme /* <default|dark|forest|neutral> */ }; /* Markdown converts to HTML */ $("pre").has("code.language-mermaid").each(function() { let svgCode = $(this).children().html(); $(this).addClass("unloaded"); $(this).after(`<div class=\"mermaid\">${svgCode}</div>`); }); mermaid.initialize(mermaidConf); window.addEventListener("message", updateMermaid); }); </script><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a><div id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true" data-animation="true" data-autohide="false"><div class="toast-header"> <button type="button" class="ml-2 ml-auto close" data-dismiss="toast" aria-label="Close"> <span aria-hidden="true">&times;</span> </button></div><div class="toast-body text-center pt-0"><p class="pl-2 pr-2 mb-3">A new version of content is available.</p><button type="button" class="btn btn-primary" aria-label="Update"> Update </button></div></div><script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No results found.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/lozad/dist/lozad.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1/dayjs.min.js,npm/dayjs@1/locale/en.min.js,npm/dayjs@1/plugin/relativeTime.min.js,npm/dayjs@1/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script>
