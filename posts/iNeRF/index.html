<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="iNeRF: Inverting Neural Radiance Fields for Pose Estimation" /><meta name="author" content="saha" /><meta property="og:locale" content="en" /><meta name="description" content="Abstract" /><meta property="og:description" content="Abstract" /><link rel="canonical" href="https://ee12ha0220.github.io/posts/iNeRF/" /><meta property="og:url" content="https://ee12ha0220.github.io/posts/iNeRF/" /><meta property="og:site_name" content="Saha’s Blog" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-02-18T00:00:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="iNeRF: Inverting Neural Radiance Fields for Pose Estimation" /><meta name="twitter:site" content="@twitter_username" /><meta name="twitter:creator" content="@saha" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"saha","url":"https://github.com/ee12ha0220/"},"dateModified":"2022-02-18T00:00:00+09:00","datePublished":"2022-02-18T00:00:00+09:00","description":"Abstract","headline":"iNeRF: Inverting Neural Radiance Fields for Pose Estimation","mainEntityOfPage":{"@type":"WebPage","@id":"https://ee12ha0220.github.io/posts/iNeRF/"},"url":"https://ee12ha0220.github.io/posts/iNeRF/"}</script><title>iNeRF: Inverting Neural Radiance Fields for Pose Estimation | Saha's Blog</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Saha's Blog"><meta name="application-name" content="Saha's Blog"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get MODE_ATTR() { return "data-mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener("change", () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } } /* ModeToggle */ const toggle = new ModeToggle(); function flipMode() { if (toggle.hasMode) { if (toggle.isSysDarkPrefer) { if (toggle.isLightMode) { toggle.clearMode(); } else { toggle.setLight(); } } else { if (toggle.isDarkMode) { toggle.clearMode(); } else { toggle.setDark(); } } } else { if (toggle.isSysDarkPrefer) { toggle.setLight(); } else { toggle.setDark(); } } toggle.notify(); } /* flipMode() */ </script><body data-spy="scroll" data-target="#toc" data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" class="mx-auto"> <img src="/assets/images/avatar_2.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Saha's Blog</a></div><div class="site-subtitle font-italic">공부한 것들을 까먹지 말자</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/ee12ha0220" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['ee12ha0220','kaist.ac.kr'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper"><div id="topbar" class="container d-flex align-items-center justify-content-between h-100 pl-3 pr-3 pl-md-4 pr-md-4"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>iNeRF: Inverting Neural Radiance Fields for Pose Estimation</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper" class="d-flex justify-content-center"><div id="main" class="container pl-xl-4 pr-xl-4"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pr-xl-4"><div class="post pl-1 pr-1 pl-md-2 pr-md-2"><h1 data-toc-skip>iNeRF: Inverting Neural Radiance Fields for Pose Estimation</h1><div class="post-meta text-muted"> <span> Posted <em class="" data-ts="1645110000" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Feb 18, 2022 </em> </span><div class="d-flex justify-content-between"> <span> By <em> <a href="https://github.com/ee12ha0220/">saha</a> </em> </span><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="1489 words"> <em>8 min</em> read</span></div></div></div><div class="post-content"><h1 id="abstract">Abstract</h1><p>We present iNeRF, a framework that performs mesh-free pose estimation by “inverting” a Neural Radiance Field (NeRF). NeRFs have been shown to be remarkably effective for the task of view synthesis — synthesizing photorealistic novel views of real-world scenes or objects. In this work, we investigate whether we can apply analysis-by-synthesis via NeRF for mesh-free, RGB-only 6DoF pose estimation – given an image, find the translation and rotation of a camera relative to a 3D object or scene. Our method assumes that no object mesh models are available during either training or test time. Starting from an initial pose estimate, we use gradient descent to minimize the residual between pixels rendered from a NeRF and pixels in an observed image. In our experiments, we first study 1) how to sample rays during pose refinement for iNeRF to collect informative gradients and 2) how different batch sizes of rays affect iNeRF on a synthetic dataset. We then show that for complex real-world scenes from the LLFF dataset, iNeRF can improve NeRF by estimating the camera poses of novel images and using these images as additional training data for NeRF. Finally, we show iNeRF can perform category level object pose estimation, including object instances not seen during training, with RGB images by inverting a NeRF model inferred from a single view.</p><h1 id="introduction">Introduction</h1><p>6 degree of freedom(6DoF) pose estimation은 다양한 분야에서 폭넓게 쓰인다. 최근에는 differentiable rendering을 기반으로 한 pose estimation이 뛰어난 성능을 보였지만, 이는 high-quality watertight 3D model을 필요로 하기 때문에 학습이 어렵고, 일반적인 object에만 적용될 수 있다는 단점이 있다. 본 논문(iNerF)에서는 novel view synthesis(NVS) 분야에서 뛰어난 성능을 보인 <a href="https://ee12ha0220.github.io/posts/NeRF/">NeRF</a>를 이용해 pose estimation을 하고자 한다. iNeRF는 특정한 scene의 image, pose, 그리고 NeRF를 통해 학습된 그 scene의 3D model을 input으로 받는데, image와 NeRF model을 통해 generate된 image를 비교하며 정확한 pose를 찾는 ‘analysis-by-synthesis’방법을 사용한다.</p><h1 id="background">Background</h1><p>NeRF–는 NeRF를 기반으로 만들어졌기 때문에, <a href="https://ee12ha0220.github.io/posts/NeRF/">NeRF</a>에 대한 내용을 확인하는 것을 추천한다.</p><h1 id="inerf-model">iNeRF model</h1><p>iNeRF는 그 이름에서 알 수 있듯이 학습된 NeRF model을 “invert”해서 특정 image의 pose를 알아내고자 한다. 즉, NeRF model의 weight $\Theta$와 image $I$가 주어졌을 때, camera pose $T$를 얻고자 한다(\ref{eq1}).</p><hr /> \[\hat{T} = \underset{T \in \text{SE}(3)}{\text{argmin }} \mathcal{L}(T|I, \Theta) \label{eq1} \tag{1}\]<hr /><p>이때 사용한 loss function은 NeRF와 동일하다. 하지만 이는 6DoF space에서 convex하지 않고, 전체 NeRF rendering이 computationally expensive 하기 때문에 약간의 수정이 필요하다.</p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 90% 90%'%3E%3C/svg%3E" data-src="/assets/images/iNeRF_1.png" width="90%" height="90%" data-proofer-ignore><em>iNeRF의 전체 framework.</em></p><h2 id="gradient-based-se3-optimization"><span class="mr-2">Gradient-Based SE(3) Optimization</span><a href="#gradient-based-se3-optimization" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>Equation \ref{eq1}에 gradient based optimization을 적용할 때, estimated pose $\hat{T}_i$는 여전히 SE(3) manifold안에 놓여 있어야 한다. 그렇기 때문에 $\hat{T}_i$를 exponential coordinate로 parameterize해서 학습을 한다(\ref{eq2}).</p><hr /> \[\begin{align} \hat{T}_i = &amp;e^{[\mathcal{S}_i]\theta_i}\hat{T}_0 \\ \text{where} \quad &amp;e^{[\mathcal{S}_i]\theta_i} = \left[ \begin{matrix} e^{[\omega]\theta} &amp; K(\mathcal{S}, \theta) \\ 0 &amp; 1 \end{matrix} \right] \end{align} \label{eq2} \tag{2}\]<hr /><p>이때 $\mathcal{S} = [\omega, \nu]^T$ 는 skew axis, $\theta$는 magnitude, $[\omega]$는 $\omega$의 $3\times3$ skew-symmetric matrix, $K(\mathcal{S}, \theta) = (I\theta+(1-\cos\theta)[\omega] + (\theta - \sin\theta)[\omega]^2)\nu$ 이다. 그러면 equation \ref{eq1}은 다음과 같이 다시 쓸 수 있다(\ref{eq3}).</p><hr /> \[\hat{\mathcal{S}\theta} = \underset{\mathcal{S}\theta \in \mathbb{R}^6}{\text{argmin }}\mathcal{L}(e^{[\mathcal{S}]\theta}T_0|I,\Theta) \label{eq3} \tag{3}\]<hr /><h2 id="sampling-rays"><span class="mr-2">Sampling rays</span><a href="#sampling-rays" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>Image에 크기에 해당하는 모든 pixel에 ray를 쏴서 volumetric rendering을 하고, 여기에 back propagation을 진행하는 것은 너무 computationally heavy 하다. 그렇기 때문에 iNeRF에서는 특정한 sampling strategy를 사용해서 전체 ray중 일부만 선택해 학습을 진행했다. 실제로 $640\times 480$크기의 image에서 2048개의 ray만 사용을 해서 학습 속도와 GPU memory 사용량을 크게 줄였다. 사용한 sampling strategy는 다음과 같다.</p><ul><li><p>Random sampling : 말 그대로 무작위로 $M$개의 ray를 골라서 사용한다. 하지만 이런 식으로 만들어진 대부분의 sample은 pose estimation에는 도움이 되지 않는 flat, textureless region에 해당했다고 한다.</p><li><p>Interest point sampling : Image alignment에서 하는 것과 비슷하게, interest point detector을 이용해 interest point를 찾아서 해당하는 ray를 사용한다. 혹시 ray에 수가 모자르다면, 남은 ray들 가운데에서 random sampling을 통해 수를 맞춰준다. 하지만 오직 interest point만 고려하기 때문에 local minima에 빠지기 쉽다.</p><li><p>Interest region sampling : Interest point sampling이 local minima에 빠지는 형상을 완화하기 위해, point가 아니라 “Interest Region”을 찾아내어 거기에서 sampling을 해준다. Interest point detector에서 interest point를 찾아내면, 거기에 $I$번의 $5\times 5$ morphological dilation을 적용해 영역을 넓혀줬다.</p></ul><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 90% 90%'%3E%3C/svg%3E" data-src="/assets/images/iNeRF_2.png" width="90%" height="90%" data-proofer-ignore><em>사용된 다양한 sampling strategy. Random 같은 경우에는 아무런 정보가 없는 공간에 많은 sample들이 위치하고 있는 것을 확인할 수 있다.</em></p><h2 id="self-supervising-nerf-with-inerf"><span class="mr-2">Self-Supervising NeRF with iNeRF</span><a href="#self-supervising-nerf-with-inerf" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>iNeRF는 pose estimation 뿐만 아니라 NeRF의 성능을 올리는 데에도 기여할 수 있다. NeRF model을 학습시킨 뒤, iNeRF를 이용해 train image들 중 pose를 모르는 image들의 pose를 알아내고, 다시 NeRF를 학습시키는 일종의 semi-supervised learning을 할 수 있다.</p><h1 id="training-details">Training details</h1><p>Synthetic dataset, LLFF dataset, ShapeNet-SRN Cars, Sim2Real Cars의 정말 많은 dataset상에서 실험을 진행했다. 더 자세한 사항은 <a href="https://arxiv.org/abs/2012.05877">iNeRF 논문</a>을 참조하길 바란다.</p><h1 id="results">Results</h1><p>Pose estimation이 성공적으로 이루어지고, self-supervising NeRF에서도 가능성을 보였다. 더 자세한 사항은 <a href="https://arxiv.org/abs/2012.05877">iNeRF 논문</a>을 참조하길 바란다.</p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 90% 90%'%3E%3C/svg%3E" data-src="/assets/images/iNeRF_3.png" width="90%" height="90%" data-proofer-ignore><em>복잡한 model을 사용하지 않고도 성공적으로 pose estimation을 해낸다.</em></p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 90% 90%'%3E%3C/svg%3E" data-src="/assets/images/iNeRF_4.png" width="90%" height="90%" data-proofer-ignore><em>전체 dataset을 사용한 것과 일부분만 사용한것, 일부분 + iNeRF을 사용한 것에 대한 비교이다. iNeRF를 사용하면 확실히 일부만 사용한 것보다는 좋은 결과가 나오는 것을 알 수 있다.</em></p><h1 id="conclusion">Conclusion</h1><p>We have presented iNeRF, a framework for mesh-free, RGB-only pose estimation that works by inverting a NeRF model. We have demonstrated that iNeRF is able to perform accurate pose estimation using gradient-based optimization. We have thoroughly investigated how to best construct minibatches of sampled rays for iNeRF and have demonstrated its performance on both synthetic and real datasets. Lastly, we have shown how iNeRF can perform category-level object pose estimation and track pose for novel object instances with an image conditioned generative NeRF model.</p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/paper-review/'>Paper review</a>, <a href='/categories/nvs/'>NVS</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=iNeRF%3A+Inverting+Neural+Radiance+Fields+for+Pose+Estimation+-+Saha%27s+Blog&url=https%3A%2F%2Fee12ha0220.github.io%2Fposts%2FiNeRF%2F" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=iNeRF%3A+Inverting+Neural+Radiance+Fields+for+Pose+Estimation+-+Saha%27s+Blog&u=https%3A%2F%2Fee12ha0220.github.io%2Fposts%2FiNeRF%2F" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2Fee12ha0220.github.io%2Fposts%2FiNeRF%2F&text=iNeRF%3A+Inverting+Neural+Radiance+Fields+for+Pose+Estimation+-+Saha%27s+Blog" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" data-title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/DDPM/">Denoising Diffusion Probabilistic Models</a><li><a href="/posts/SMLD/">Generative Modeling by Estimating Gradients of the Data Distribution</a><li><a href="/posts/DDIM/">DENOISING DIFFUSION IMPLICIT MODELS</a><li><a href="/posts/fn/">각종 코드 정리</a><li><a href="/posts/MLMC/">A Machine Learning Approach for Filtering Monte Carlo Noise</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/tag/">tag</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 pl-3 pr-3 pr-xl-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/NeRF/"><div class="card-body"> <em class="small" data-ts="1641308400" data-df="ll" > Jan 5, 2022 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis</h3><div class="text-muted small"><p> Abstract We present a method that achieves state-of-the-art results for synthesizing novel views of complex scenes by optimizing an underlying continuous volumetric scene function using a sparse s...</p></div></div></a></div><div class="card"> <a href="/posts/NeRFpp/"><div class="card-body"> <em class="small" data-ts="1641999600" data-df="ll" > Jan 13, 2022 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>NERF++: ANALYZING AND IMPROVING NEURAL RADIANCE FIELDS</h3><div class="text-muted small"><p> Abstract Neural Radiance Fields (NeRF) achieve impressive view synthesis results for a variety of capture settings, including 360◦ capture of bounded scenes and forward-facing capture of bounded a...</p></div></div></a></div><div class="card"> <a href="/posts/NeRFmm/"><div class="card-body"> <em class="small" data-ts="1642863600" data-df="ll" > Jan 23, 2022 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>NeRF−−: Neural Radiance Fields Without Known Camera Parameters</h3><div class="text-muted small"><p> Abstract This paper tackles the problem of novel view synthesis (NVS) from 2D images without known camera poses or intrinsics. Among various NVS techniques, Neural Radiance Field (NeRF) has recent...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/OmniNeRF/" class="btn btn-outline-primary" prompt="Older"><p>Moving in a 360 World : Synthesizing Panoramic Parallaxes from a Single Panorama(OmniNeRF)</p></a> <a href="/posts/KPCN/" class="btn btn-outline-primary" prompt="Newer"><p>Kernel-Predicting Convolutional Networks for Denoising Monte Carlo Renderings</p></a></div></div></div><footer class="row pl-3 pr-3"><div class="col-12 d-flex justify-content-between align-items-center text-muted pl-0 pr-0"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://twitter.com/username">Seeha Lee</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/tag/">tag</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><script src="https://cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js"></script> <script> $(function() { function updateMermaid(event) { if (event.source === window && event.data && event.data.direction === ModeToggle.ID) { const mode = event.data.message; if (typeof mermaid === "undefined") { return; } let expectedTheme = (mode === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* Re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } let initTheme = "default"; if ($("html[data-mode=dark]").length > 0 || ($("html[data-mode]").length == 0 && window.matchMedia("(prefers-color-scheme: dark)").matches ) ) { initTheme = "dark"; } let mermaidConf = { theme: initTheme /* <default|dark|forest|neutral> */ }; /* Markdown converts to HTML */ $("pre").has("code.language-mermaid").each(function() { let svgCode = $(this).children().html(); $(this).addClass("unloaded"); $(this).after(`<div class=\"mermaid\">${svgCode}</div>`); }); mermaid.initialize(mermaidConf); window.addEventListener("message", updateMermaid); }); </script><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a><div id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true" data-animation="true" data-autohide="false"><div class="toast-header"> <button type="button" class="ml-2 ml-auto close" data-dismiss="toast" aria-label="Close"> <span aria-hidden="true">&times;</span> </button></div><div class="toast-body text-center pt-0"><p class="pl-2 pr-2 mb-3">A new version of content is available.</p><button type="button" class="btn btn-primary" aria-label="Update"> Update </button></div></div><script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No results found.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/lozad/dist/lozad.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1/dayjs.min.js,npm/dayjs@1/locale/en.min.js,npm/dayjs@1/plugin/relativeTime.min.js,npm/dayjs@1/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script>
